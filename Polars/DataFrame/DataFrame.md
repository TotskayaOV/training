# DataFrame

На этой странице представлен обзор всех методов создания общедоступных фреймов данных.

class polars.**DataFrame**(
    
    data: FrameInitTypes | None = None, 
    schema: SchemaDefinition | None = None, *, 
    schema_overrides: SchemaDict | None = None, 
    orient: Orientation | None = None, 
    infer_schema_length: int | None = 100, 
    nan_to_null: bool = False)

Двумерная структура данных, представляющая данные в виде таблицы со строками и столбцами.

**Параметры:**

**data:** *dict, Sequence, ndarray, Series, or pandas.DataFrame*

Двумерные данные в различных формах; вводимые данные dict должны содержать последовательности, генераторы или диапазон. Последовательность может содержать Series или другие последовательности.

**schema:** *Sequence of str, (str,DataType) pairs, or a {str:DataType,} dict*

Схема фрейма данных может быть объявлена несколькими способами:

* Как указатель пар `{name:type}`; если тип равен None, он будет выведен автоматически.

* В виде списка имен столбцов; в этом случае автоматически выводятся типы.

* В виде списка пар `{name:type}`; это эквивалентно форме словаря.

Если вы предоставите список имен столбцов, который не соответствует именам в базовых данных, приведенные здесь имена будут заменены на них. Количество имен, указанных в схеме, должно соответствовать базовым измерениям данных.

**schema_overrides:** *dict, default None*

Поддерживайте спецификацию типа или переопределение одного или нескольких столбцов; обратите внимание, что любые типы, выведенные из параметра `schema`, будут переопределены. базовые данные, приведенные здесь имена заменят их.

Количество записей в схеме должно соответствовать базовым измерениям данных, если только не передается последовательность словарей, и в этом случае может быть объявлена `_partial_ schema`, чтобы предотвратить загрузку определенных полей.

**orient:** *{‘col’, ‘row’}, default None*

Следует ли интерпретировать двумерные данные в виде столбцов или строк. Если нет, ориентация определяется путем сопоставления столбцов и измерений данных. Если это не дает окончательных результатов, используется ориентация столбцов.

**infer_schema_length:** *int, default None*

Максимальное количество строк, считываемых для вывода схемы; применяется только в том случае, если входные данные представляют собой последовательность или генератор строк; остальные входные данные считываются как есть.

**nan_to_null:** *bool, default False*

Если данные поступают из одного или нескольких массивов numpy, можно дополнительно преобразовать значения входных данных `np.nan` в `null` вместо этого. Это не относится ко всем остальным входным данным.

Примечания:

Некоторые методы внутренне преобразуют DataFrame в LazyFrame, прежде чем собирать результаты обратно в DataFrame. Это может привести к неожиданному поведению при использовании подклассифицированного DataFrame. Например:

```
class MyDataFrame(pl.DataFrame):
    pass

isinstance(MyDataFrame().lazy().collect(), MyDataFrame)
False
```

Примеры:

Построение фрейма данных из словаря:

```
data = {"a": [1, 2], "b": [3, 4]}
df = pl.DataFrame(data)
df
shape: (2, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 3   │
│ 2   ┆ 4   │
└─────┴─────┘
```

Обратите внимание, что типы автоматически выводятся как `polars Int64`:

```
df.dtypes
[Int64, Int64]
```

Чтобы указать более подробную/конкретную схему фрейма, вы можете указать в параметре schema словарь пар (name,dtype) ...

```
data = {"col1": [0, 2], "col2": [3, 7]}
df2 = pl.DataFrame(data, schema={"col1": pl.Float32, "col2": pl.Int64})
df2
shape: (2, 2)
┌──────┬──────┐
│ col1 ┆ col2 │
│ ---  ┆ ---  │
│ f32  ┆ i64  │
╞══════╪══════╡
│ 0.0  ┆ 3    │
│ 2.0  ┆ 7    │
└──────┴──────┘
```

…последовательность пар (name,dtype) …

```
data = {"col1": [1, 2], "col2": [3, 4]}
df3 = pl.DataFrame(data, schema=[("col1", pl.Float32), ("col2", pl.Int64)])
df3
shape: (2, 2)
┌──────┬──────┐
│ col1 ┆ col2 │
│ ---  ┆ ---  │
│ f32  ┆ i64  │
╞══════╪══════╡
│ 1.0  ┆ 3    │
│ 2.0  ┆ 4    │
└──────┴──────┘
```

…или список набранных Series.

```
data = [
    pl.Series("col1", [1, 2], dtype=pl.Float32),
    pl.Series("col2", [3, 4], dtype=pl.Int64),
]
df4 = pl.DataFrame(data)
df4
shape: (2, 2)
┌──────┬──────┐
│ col1 ┆ col2 │
│ ---  ┆ ---  │
│ f32  ┆ i64  │
╞══════╪══════╡
│ 1.0  ┆ 3    │
│ 2.0  ┆ 4    │
└──────┴──────┘
```

Построение фрейма данных из numpy ndarray с указанием имен столбцов:

```
import numpy as np
data = np.array([(1, 2), (3, 4)], dtype=np.int64)
df5 = pl.DataFrame(data, schema=["a", "b"], orient="col")
df5
shape: (2, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 3   │
│ 2   ┆ 4   │
└─────┴─────┘
```
Построение DataFrame из списка списков с выводом ориентации строк:

```
data = [[1, 2, 3], [4, 5, 6]]
df6 = pl.DataFrame(data, schema=["a", "b", "c"])
df6
shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ 1   ┆ 2   ┆ 3   │
│ 4   ┆ 5   ┆ 6   │
└─────┴─────┴─────┘
```

## Методы:
______________________________________

**apply** Примените пользовательскую функцию (UDF) к строкам DataFrame.
____________________________________________________
**bottom_k** Возвращает k наименьших элементов.
______________________________________________
**clear** Создайте пустую (n=0) или n-строчную, заполненную нулем (n>0) копию фрейма данных.
____________________________________________
**clone** Дешевая глубокая копия/клонирование.
____________________________________________
**corr** Возвращает коэффициенты корреляции произведения Пирсона-момента.
____________________________________________
**describe** Сводная статистика для фрейма данных.
____________________________________________
**drop** Удалите столбцы из фрейма данных.
____________________________________________
**drop_in_place** Поместите один столбец на место и верните удаленный столбец.
____________________________________________
**drop_nulls** Удалите все строки, содержащие нулевые значения.
____________________________________________
**estimated_size** возвращает оценку общего размера (кучи), выделенного для фрейма данных.
____________________________________________
**explode** Разнесите фрейм данных в длинный формат путем разнесения заданных столбцов.
____________________________________________
**extend** Расширьте память, поддерживаемую этим фреймом данных, значениями из других.
____________________________________________
**fill_nan** Заполните значения NaN с плавающей запятой с помощью вычисления выражения.
____________________________________________
**fill_null** Заполните нулевые значения, используя указанное значение или стратегию.
____________________________________________
**filter** Фильтруйте строки во фрейме данных на основе выражения предиката.
____________________________________________
**find_idx_by_name** Найдите индекс столбца по имени.
____________________________________________
**fold** Примените горизонтальное уменьшение к фрейму данных.
____________________________________________
**frame_equal** Проверьте, равен ли фрейм данных другому.
____________________________________________
**get_column** Получите один столбец в виде серии по имени.
____________________________________________
**get_columns** Получите фрейм данных в виде списка серий.
____________________________________________
**glimpse** Возвращает плотный предварительный просмотр фрейма данных.
____________________________________________
**groupby** Создайте группу по операции.
____________________________________________
**groupby_dynamic** Группируйте на основе значения времени (или значения индекса типа Int32, Int64).
____________________________________________
**groupby_rolling** CСоздавайте переходящие группы на основе столбца time, Int32 или Int64.
____________________________________________
**hash_rows** Хэшируйте и объединяйте строки в этом фрейме данных.
____________________________________________
**head** Получите первые n строк.
____________________________________________
**hstack** Верните новый фрейм данных, увеличенный горизонтально путем добавления к нему нескольких рядов.
____________________________________________
**insert_at_idx** Вставьте серию с определенным индексом столбца. Эта операция уже проведена.
____________________________________________
**interpolate** Интерполируйте промежуточные значения.
____________________________________________
**is_duplicated** Получите маску всех дублированных строк в этом фрейме данных.
____________________________________________
**is_empty** Проверьте, пуст ли фрейм данных.
____________________________________________
**is_unique** Получите маску всех уникальных строк в этом фрейме данных.
____________________________________________
**item** Верните фрейм данных в виде скаляра или верните элемент в заданной строке/столбце.
____________________________________________
**iter_rows** Возвращает итератор по фрейму данных из строк собственных значений python.
____________________________________________
**iter_slices** Возвращает некопирующий итератор фрагментов по базовому фрейму данных.
____________________________________________
**join** Присоединяйтесь в SQL-подобном режиме.
____________________________________________
**join_asof** Perform an asof join.
____________________________________________
**lazy** Запустите отложенный запрос с этого момента.
____________________________________________
**limit** Получите первые n строк.
____________________________________________
**max** Агрегируйте столбцы этого фрейма данных до их максимального значения.
____________________________________________
**mean** Агрегируйте столбцы этого фрейма данных по их среднему значению.
____________________________________________
**median** Агрегируйте столбцы этого фрейма данных по их среднему значению.
____________________________________________
**melt** Откорректируйте фрейм данных из широкого формата в длинный.
____________________________________________
**merge_sorted** Возьмите два отсортированных фрейма данных и объедините их по отсортированному ключу.
____________________________________________
**min** Aggregate the columns of this DataFrame to their minimum value.
____________________________________________
**n_chunks** Получите количество фрагментов, используемых фрагментированными массивами этого фрейма данных.
____________________________________________
**n_unique** Возвращает количество уникальных строк или количество уникальных подмножеств строк.
____________________________________________
**null_count** Создайте новый фрейм данных, который показывает количество нулей в каждом столбце.
____________________________________________
**partition_by** Сгруппируйте по заданным столбцам и верните группы в виде отдельных фреймов данных.
____________________________________________
**pipe** Предлагает структурированный способ применения последовательности пользовательских функций (UDFS).
____________________________________________
**pivot** Создайте сводную таблицу в стиле электронной таблицы в качестве фрейма данных.
____________________________________________
**product** Агрегируйте столбцы этого фрейма данных с их значениями продукта.
____________________________________________
**quantile** Агрегируйте столбцы этого фрейма данных по их квантильному значению.
____________________________________________
**rechunk** Повторно распределите данные в этом фрейме данных по непрерывному распределению.
____________________________________________
**rename** Переименуйте имена столбцов.
____________________________________________
**replace** Замените столбец новой серией.
____________________________________________
**replace_at_idx** Replace a column at an index location.
____________________________________________
**reverse** Переверните фрейм данных.
____________________________________________
**row** Получите значения одной строки либо по индексу, либо по предикату.
____________________________________________
**rows** Возвращает все данные в DataFrame в виде списка строк собственных значений python.
____________________________________________
**sample** Выборка из этого фрейма данных.
____________________________________________
**select** Выберите столбцы из этого фрейма данных.
____________________________________________
**set_sorted** Укажите, что один или несколько столбцов отсортированы.
____________________________________________
**shift** Сдвиг значений на заданный период.
____________________________________________
**shift_and_fill** Сдвиньте значения на заданный период и заполните полученные значения null.
____________________________________________
**shrink_to_fit** Сократите использование памяти фрейма данных.
____________________________________________
**slice** Получите фрагмент этого фрейма данных.
____________________________________________
**sort** Отсортируйте фрейм данных по заданным столбцам.
--------
**std** Агрегируйте столбцы этого фрейма данных по их значению стандартного отклонения.
____________________________________________
**sum** Суммируйте столбцы этого фрейма данных до их суммарного значения.
____________________________________________
**tail** Получаем последние n строк.
____________________________________________
**take_every** Возьмите каждую n-ю строку в DataFrame и верните как новый DataFrame.
____________________________________________
**to_arrow** Соберите лежащие в основе массивы массивов в таблицу массивов.
____________________________________________
**to_dict** Преобразуйте фрейм данных в словарь, сопоставляющий имя столбца значениям.
____________________________________________
**to_dicts** Преобразуйте каждую строку в словарь собственных значений python.
____________________________________________
**to_dummies** Преобразуйте категориальные переменные в фиктивные/индикаторные переменные.
____________________________________________
**to_init_repr** Преобразуйте фрейм данных в создаваемое строковое представление.
____________________________________________
**to_numpy** Преобразуйте фрейм данных в двумерный массив NumPy.
____________________________________________
**to_pandas** Приведение к фрейму данных pandas.
____________________________________________
**to_series** Выберите столбец как Series в расположении индекса.
____________________________________________
**to_struct** Преобразуйте фрейм данных в последовательность типов Struct.
____________________________________________
**top_k** Возвращает k самых больших элементов.
____________________________________________
**transpose** Транспонировать фрейм данных по диагонали.
____________________________________________
**unique** Удалите повторяющиеся строки из этого фрейма данных.
____________________________________________
**unnest** Разложите столбцы структуры на отдельные столбцы для каждого из их полей.
____________________________________________
**unstack** Преобразуйте длинную таблицу в широкую форму, не выполняя агрегирование.
____________________________________________
**update** Обновите значения в этом фрейме данных ненулевыми значениями в другом.
____________________________________________
**upsample** Повышайте выборку фрейма данных с регулярной частотой.
____________________________________________
**var** Агрегируйте столбцы этого фрейма данных по их значению дисперсии.
____________________________________________
**vstack** Увеличьте этот фрейм данных по вертикали, наложив на него фрейм данных.
____________________________________________
**with_columns** Добавьте столбцы в этот фрейм данных.
____________________________________________
**with_row_count** Добавьте столбец с индексом 0, который подсчитывает строки.
____________________________________________
**write_avro** Запишите в файл Apache Avro.
____________________________________________
**write_csv** Запись в файл значений, разделенных запятыми (CSV).
____________________________________________
**write_database** Запишите фрейм polars в базу данных.
____________________________________________
**write_delta** Запишите фрейм данных в виде дельта-таблицы.
____________________________________________
**write_excel** Запишите данные фрейма в таблицу в Excel книге / рабочем листе.
____________________________________________
**write_ipc** Запишите в двоичный поток Arrow IPC или файл Feather.
____________________________________________
**write_json** Сериализовать в JSON-представление.
____________________________________________
**write_ndjson** Сериализовать в JSON-представление с разделителями новой строки.
____________________________________________
**write_parquet** Запишите в файл Apache Parquet.
________________________________________________________


## **Атрибуты:**

|атрибут| описание |
|-------------|----------|
| columns | Получить или задать имена столбцов.|
| dtypes | Получите типы данных столбцов этого фрейма данных. |
| height | Получите высоту фрейма данных.
| schema | Получите dict[имя столбца, тип данных].
| shape | Получите форму фрейма данных.
| width | Получите ширину фрейма данных.

# apply (

    function: Callable[[tuple[Any, ...]], Any], 
    return_dtype: PolarsDataType | None = None, *, 
    inference_size: int = 256
) → DataFrame

Примените пользовательскую функцию (UDF) к строкам DataFrame.

UDF получит каждую строку в виде кортежа значений: udf(row).

Реализация логики с использованием функции Python почти всегда значительно медленнее и требует больше памяти, чем реализация той же логики с использованием native expression API, поскольку:

Движок собственных выражений работает на Rust; UDFs работают на Python.

Использование Python UDFs приводит к тому, что DataFrame материализуется в памяти.

Polars-native выражения могут быть распараллелены (UDFs обычно не могут).

Polars-native выражения могут быть логически оптимизированы (UDFs - нет).

Везде, где это возможно, вы должны отдавать предпочтение native expression API для достижения наилучшей производительности.

**Параметры:**

**function**

Пользовательская функция или lambda.

**return_dtype**

Тип вывода операции. Если ничего не указано, Polaris пытается определить тип.

**inference_size**

Используется только в том случае, когда пользовательская функция возвращает строки. При этом используются первые n строк для определения выходной схемы

**Примечание:**

Применение на уровне фрейма не может отслеживать имена столбцов (поскольку UDF - это черный ящик, который может произвольно удалять, переставлять, преобразовывать или добавлять новые столбцы); если вы хотите применить UDF таким образом, чтобы имена столбцов были сохранены, вам следует вместо этого использовать синтаксис применения на уровне выражений.

Если ваша функция дорогая и вы не хотите, чтобы она вызывалась более одного раза для заданных входных данных, рассмотрите возможность применения к ней декоратора `@lru_cache`. Располагая подходящими данными, вы можете добиться ускорения на порядок (или более).

**Например:**
```
df = pl.DataFrame({"foo": [1, 2, 3], "bar": [-1, 5, 8]})
```
Возвращает фрейм данных, сопоставляя каждую строку с кортежем:
```
df.apply(lambda t: (t[0] * 2, t[1] * 3))
shape: (3, 2)
┌──────────┬──────────┐
│ column_0 ┆ column_1 │
│ ---      ┆ ---      │
│ i64      ┆ i64      │
╞══════════╪══════════╡
│ 2        ┆ -3       │
│ 4        ┆ 15       │
│ 6        ┆ 24       │
└──────────┴──────────┘
```
Лучше реализовать это с помощью выражения:
```
df.select(
    pl.col("foo") * 2,
    pl.col("bar") * 3,
)  
```
Возвращает ряд, сопоставляя каждую строку со скалярным значением:
```
df.apply(lambda t: (t[0] * 2 + t[1]))
shape: (3, 1)
┌───────┐
│ apply │
│ ---   │
│ i64   │
╞═══════╡
│ 1     │
│ 9     │
│ 14    │
└───────┘
```
В этом случае лучше использовать следующее выражение:
```
df.select(pl.col("foo") * 2 + pl.col("bar")) 
```

### bottom_k (
    
    k: int, *, 
    by: IntoExpr | Iterable[IntoExpr], 
    descending: bool | Sequence[bool] = False, 
    nulls_last: bool = False
) → DataFrame

Возвращает k наименьших элементов.

Если `descending=True`, то будут даны самые большие элементы.

**Параметры:**

`k` - Количество возвращаемых строк.

`by` - Столбцы, включенные в порядке сортировки. Принимает ввод выражения. Строки анализируются как имена столбцов.

`descending` - Верните наименьшее значение ‘k’. Top-k по нескольким столбцам может быть задан для каждого столбца путем передачи последовательности логических значений.

`nulls_last` Размещайте нулевые значения последними.


Например
```
df = pl.DataFrame(
    {
        "a": ["a", "b", "a", "b", "b", "c"],
        "b": [2, 1, 1, 3, 2, 1],
    }
)
```
Получите строки, которые содержат 4 наименьших значения в столбце b.
```
df.bottom_k(4, by="b")
shape: (4, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ b   ┆ 1   │
│ a   ┆ 1   │
│ c   ┆ 1   │
│ a   ┆ 2   │
└─────┴─────┘
```
Получите строки, которые содержат 4 наименьших значения при сортировке по столбцам a и b.
```
df.bottom_k(4, by=["a", "b"])
shape: (4, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ a   ┆ 1   │
│ a   ┆ 2   │
│ b   ┆ 1   │
│ b   ┆ 2   │
└─────┴─────┘
```
### clear(
    n: int = 0
) → Self

Создайте пустую `(n=0)` или n-строчную, заполненную нулем `(n>0)` копию фрейма данных.

Возвращает n-строчный фрейм данных, заполненный нулем, с идентичной схемой. n может быть больше текущего количества строк во фрейме данных.

**Параметры:**

`n` - Количество строк (заполненных нулем), возвращаемых в очищенном фрейме.

Пример:
```
df = pl.DataFrame(
    {
        "a": [None, 2, 3, 4],
        "b": [0.5, None, 2.5, 13],
        "c": [True, True, False, None],
    }
)
df.clear()
shape: (0, 3)
┌─────┬─────┬──────┐
│ a   ┆ b   ┆ c    │
│ --- ┆ --- ┆ ---  │
│ i64 ┆ f64 ┆ bool │
╞═════╪═════╪══════╡
└─────┴─────┴──────┘
df.clear(n=2)
shape: (2, 3)
┌──────┬──────┬──────┐
│ a    ┆ b    ┆ c    │
│ ---  ┆ ---  ┆ ---  │
│ i64  ┆ f64  ┆ bool │
╞══════╪══════╪══════╡
│ null ┆ null ┆ null │
│ null ┆ null ┆ null │
└──────┴──────┴──────┘
```
### clone(

) → Self

Дешевая глубокая копия/клонирование.

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 2, 3, 4],
        "b": [0.5, 4, 10, 13],
        "c": [True, True, False, True],
    }
)
df.clone()
shape: (4, 3)
┌─────┬──────┬───────┐
│ a   ┆ b    ┆ c     │
│ --- ┆ ---  ┆ ---   │
│ i64 ┆ f64  ┆ bool  │
╞═════╪══════╪═══════╡
│ 1   ┆ 0.5  ┆ true  │
│ 2   ┆ 4.0  ┆ true  │
│ 3   ┆ 10.0 ┆ false │
│ 4   ┆ 13.0 ┆ true  │
└─────┴──────┴───────┘
```
свойство **columns:** *list[str]*

Получить или задать имена столбцов.

Пример
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.columns
['foo', 'bar', 'ham']
```
Задать имена столбцов:
```
df.columns = ["apple", "banana", "orange"]
df
shape: (3, 3)
┌───────┬────────┬────────┐
│ apple ┆ banana ┆ orange │
│ ---   ┆ ---    ┆ ---    │
│ i64   ┆ i64    ┆ str    │
╞═══════╪════════╪════════╡
│ 1     ┆ 6      ┆ a      │
│ 2     ┆ 7      ┆ b      │
│ 3     ┆ 8      ┆ c      │
└───────┴────────┴────────┘
```
### *corr*(
    
    **kwargs: Any
) → DataFrame

Возвращает коэффициенты корреляции произведения Пирсона-момента.

[См. numpy corrcoef для получения дополнительной информации](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html)

**Параметры:**

`**kwargs` аргументы ключевого слова передаются в numpy corrcoef

*Примечание*

*Для этой функции требуется установка numpy.*

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3], "bar": [3, 2, 1], "ham": [7, 8, 9]})
df.corr()
shape: (3, 3)
┌──────┬──────┬──────┐
│ foo  ┆ bar  ┆ ham  │
│ ---  ┆ ---  ┆ ---  │
│ f64  ┆ f64  ┆ f64  │
╞══════╪══════╪══════╡
│ 1.0  ┆ -1.0 ┆ 1.0  │
│ -1.0 ┆ 1.0  ┆ -1.0 │
│ 1.0  ┆ -1.0 ┆ 1.0  │
└──────┴──────┴──────┘
```
### **describe(**

    percentiles: Sequence[float] | float | None = (0.25, 0.75)
) → Self

Сводная статистика для фрейма данных.

**Параметры:**

`percentiles` Один или несколько процентилей для включения в сводную статистику. Все значения должны находиться в диапазоне [0, 1].

Пример:
```
from datetime import date
df = pl.DataFrame(
    {
        "a": [1.0, 2.8, 3.0],
        "b": [4, 5, None],
        "c": [True, False, True],
        "d": [None, "b", "c"],
        "e": ["usd", "eur", None],
        "f": [date(2020, 1, 1), date(2021, 1, 1), date(2022, 1, 1)],
    }
)
df.describe()
shape: (9, 7)
┌────────────┬──────────┬──────────┬──────────┬──────┬──────┬────────────┐
│ describe   ┆ a        ┆ b        ┆ c        ┆ d    ┆ e    ┆ f          │
│ ---        ┆ ---      ┆ ---      ┆ ---      ┆ ---  ┆ ---  ┆ ---        │
│ str        ┆ f64      ┆ f64      ┆ f64      ┆ str  ┆ str  ┆ str        │
╞════════════╪══════════╪══════════╪══════════╪══════╪══════╪════════════╡
│ count      ┆ 3.0      ┆ 3.0      ┆ 3.0      ┆ 3    ┆ 3    ┆ 3          │
│ null_count ┆ 0.0      ┆ 1.0      ┆ 0.0      ┆ 1    ┆ 1    ┆ 0          │
│ mean       ┆ 2.266667 ┆ 4.5      ┆ 0.666667 ┆ null ┆ null ┆ null       │
│ std        ┆ 1.101514 ┆ 0.707107 ┆ 0.57735  ┆ null ┆ null ┆ null       │
│ min        ┆ 1.0      ┆ 4.0      ┆ 0.0      ┆ b    ┆ eur  ┆ 2020-01-01 │
│ max        ┆ 3.0      ┆ 5.0      ┆ 1.0      ┆ c    ┆ usd  ┆ 2022-01-01 │
│ median     ┆ 2.8      ┆ 4.5      ┆ 1.0      ┆ null ┆ null ┆ null       │
│ 25%        ┆ 1.0      ┆ 4.0      ┆ null     ┆ null ┆ null ┆ null       │
│ 75%        ┆ 3.0      ┆ 5.0      ┆ null     ┆ null ┆ null ┆ null       │
└────────────┴──────────┴──────────┴──────────┴──────┴──────┴────────────┘
```
### **drop(**

    columns: str | Collection[str], *more_columns: str
) → DataFrame[source]

Удалите столбцы из фрейма данных.

**Параметры:**

`columns` Имя столбца (столбцов), которые должны быть удалены из фрейма данных.

`*more_columns` Дополнительные столбцы для удаления, указанные в качестве позиционных аргументов.

Пример:

Удалите один столбец, передав имя этого столбца.
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
df.drop("ham")
shape: (3, 2)
┌─────┬─────┐
│ foo ┆ bar │
│ --- ┆ --- │
│ i64 ┆ f64 │
╞═════╪═════╡
│ 1   ┆ 6.0 │
│ 2   ┆ 7.0 │
│ 3   ┆ 8.0 │
└─────┴─────┘
```
Удалите несколько столбцов, передав список имен столбцов.
```
df.drop(["bar", "ham"])
shape: (3, 1)
┌─────┐
│ foo │
│ --- │
│ i64 │
╞═════╡
│ 1   │
│ 2   │
│ 3   │
└─────┘
```
Или используйте позиционные аргументы, чтобы удалить несколько столбцов одним и тем же способом.
```
df.drop("foo", "bar")
shape: (3, 1)
┌─────┐
│ ham │
│ --- │
│ str │
╞═════╡
│ a   │
│ b   │
│ c   │
└─────┘
```
### **drop_in_place(**

    name: str
) → Series[source]

Поместите один столбец на место и верните удаленный столбец.

**Параметры:**

`name` Название столбца, который нужно удалить.

Returns: удаленный столбец.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.drop_in_place("ham")
shape: (3,)
Series: 'ham' [str]
[
    "a"
    "b"
    "c"
]
```
### **drop_nulls(**
    
    subset: str | Collection[str] | None = None
) → DataFrame[source]

Удалите все строки, содержащие нулевые значения.

Возвращает новый фрейм данных.

**Параметры:**

`subset` Имена столбцов, для которых учитываются нулевые значения. Если задано значение None (по умолчанию), используются все столбцы.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, None, 8],
        "ham": ["a", "b", "c"],
    }
)
df.drop_nulls()
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ a   │
│ 3   ┆ 8   ┆ c   │
└─────┴─────┴─────┘
```
Этот метод удаляет строки, в которых любое отдельное значение строки равно null.

Ниже приведены несколько примеров фрагментов, которые показывают, как вы могли бы удалить нулевые значения на основе других условий
```
df = pl.DataFrame(
    {
        "a": [None, None, None, None],
        "b": [1, 2, None, 1],
        "c": [1, None, None, 1],
    }
)
df
shape: (4, 3)
┌──────┬──────┬──────┐
│ a    ┆ b    ┆ c    │
│ ---  ┆ ---  ┆ ---  │
│ f32  ┆ i64  ┆ i64  │
╞══════╪══════╪══════╡
│ null ┆ 1    ┆ 1    │
│ null ┆ 2    ┆ null │
│ null ┆ null ┆ null │
│ null ┆ 1    ┆ 1    │
└──────┴──────┴──────┘
```
Удаляйте строку только в том случае, если все значения равны нулю:
```
df.filter(~pl.all(pl.all().is_null()))
shape: (3, 3)
┌──────┬─────┬──────┐
│ a    ┆ b   ┆ c    │
│ ---  ┆ --- ┆ ---  │
│ f32  ┆ i64 ┆ i64  │
╞══════╪═════╪══════╡
│ null ┆ 1   ┆ 1    │
│ null ┆ 2   ┆ null │
│ null ┆ 1   ┆ 1    │
└──────┴─────┴──────┘
```
Удалите столбец, если все значения равны нулю:
```
df[[s.name for s in df if not (s.null_count() == df.height)]]
shape: (4, 2)
┌──────┬──────┐
│ b    ┆ c    │
│ ---  ┆ ---  │
│ i64  ┆ i64  │
╞══════╪══════╡
│ 1    ┆ 1    │
│ 2    ┆ null │
│ null ┆ null │
│ 1    ┆ 1    │
└──────┴──────┘
```
свойство **dtypes:** *list[PolarsDataType]*

Получите типы данных столбцов этого фрейма данных.

Типы данных также можно найти в заголовках столбцов при печати фрейма данных.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
df.dtypes
[Int64, Float64, Utf8]
df
shape: (3, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6.0 ┆ a   │
│ 2   ┆ 7.0 ┆ b   │
│ 3   ┆ 8.0 ┆ c   │
└─────┴─────┴─────┘
```
### **estimated_size**(
    
    unit: SizeUnit = 'b'
) → int | float

возвращает оценку общего размера (кучи), выделенного для фрейма данных.

Предполагаемый размер указан в указанных единицах измерения (по умолчанию в байтах).

Эта оценка представляет собой сумму размера его буферов, валидности, включая вложенные массивы. Несколько массивов могут совместно использовать буферы и растровые изображения. Следовательно, размер 2 массивов не является суммой размеров, вычисленных с помощью этой функции. В частности, размер [StructArray] является верхней границей.

Когда массив разрезается, его выделенный размер остается постоянным, поскольку буфер остается неизменным. Однако эта функция выдаст меньшее число. Это связано с тем, что эта функция возвращает видимый размер буфера, а не его общую емкость.

Буферы FFI включены в эту оценку.

**Параметры:**

`unit {‘b’, ‘kb’, ‘mb’, ‘gb’, ‘tb’}` Масштабируйте возвращаемый размер до заданной единицы измерения.

Пример:
```
df = pl.DataFrame(
    {
        "x": list(reversed(range(1_000_000))),
        "y": [v / 1000 for v in range(1_000_000)],
        "z": [str(v) for v in range(1_000_000)],
    },
    schema=[("x", pl.UInt32), ("y", pl.Float64), ("z", pl.Utf8)],
)
df.estimated_size()
25888898
df.estimated_size("mb")
24.689577102661133
```
### **explode(**

    columns: str | Sequence[str] | Expr | Sequence[Expr], 
    *more_columns: str | Expr
) → DataFrame

Разнесите фрейм данных в длинный формат путем разнесения заданных столбцов.

**Параметры:**

`columns` Имя столбца (столбцов), который(которые) необходимо разнесать. Столбцы должны иметь тип данных List или Utf 8. Также принимает выражения col в качестве входных данных.

`*more_columns` Дополнительные имена столбцов для разнесения, указанные в качестве позиционных аргументов.

Returns: DataFrame

Пример:
```
df = pl.DataFrame(
    {
        "letters": ["a", "a", "b", "c"],
        "numbers": [[1], [2, 3], [4, 5], [6, 7, 8]],
    }
)
df
shape: (4, 2)
┌─────────┬───────────┐
│ letters ┆ numbers   │
│ ---     ┆ ---       │
│ str     ┆ list[i64] │
╞═════════╪═══════════╡
│ a       ┆ [1]       │
│ a       ┆ [2, 3]    │
│ b       ┆ [4, 5]    │
│ c       ┆ [6, 7, 8] │
└─────────┴───────────┘
df.explode("numbers")
shape: (8, 2)
┌─────────┬─────────┐
│ letters ┆ numbers │
│ ---     ┆ ---     │
│ str     ┆ i64     │
╞═════════╪═════════╡
│ a       ┆ 1       │
│ a       ┆ 2       │
│ a       ┆ 3       │
│ b       ┆ 4       │
│ b       ┆ 5       │
│ c       ┆ 6       │
│ c       ┆ 7       │
│ c       ┆ 8       │
└─────────┴─────────┘
```
### **extend(**

    other: Self
) → Self

Расширьте память, поддерживаемую этим фреймом данных, значениями из других.

В отличие от vstack, который добавляет фрагменты из other к фрагментам этого фрейма данных, расширение добавляет данные из other в базовые ячейки памяти и, таким образом, может вызвать перераспределение.

Если это не приведет к перераспределению, результирующая структура данных не будет содержать никаких дополнительных блоков и, таким образом, приведет к более быстрым запросам.

Предпочитайте расширять по сравнению с vstack, когда вы хотите выполнить запрос после одного добавления. Например, во время онлайн-операций, когда вы добавляете n строк и повторно запускаете запрос.

Предпочитайте vstack, а не extend, когда вы хотите добавлять много раз перед выполнением запроса. Например, когда вы читаете в нескольких файлах и когда нужно сохранить их в одном фрейме данных. В последнем случае завершите последовательность операций vstack повторной загрузкой.

**Параметры:**

`other` Фрейм данных для добавления по вертикали.

Пример:
```
df1 = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
df2 = pl.DataFrame({"foo": [10, 20, 30], "bar": [40, 50, 60]})
df1.extend(df2)
shape: (6, 2)
┌─────┬─────┐
│ foo ┆ bar │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 4   │
│ 2   ┆ 5   │
│ 3   ┆ 6   │
│ 10  ┆ 40  │
│ 20  ┆ 50  │
│ 30  ┆ 60  │
└─────┴─────┘
```
### **fill_nan(**
    
    value: Expr | int | float | None
) → DataFrame

Заполните значения NaN с плавающей запятой с помощью вычисления выражения.

**Параметры:**

`value` Значение для заполнения NaN.

Возвращает: Фрейм данных с NaN заменен на fill_value

*Внимание*

*Обратите внимание, что NAN с плавающей запятой (не число) не являются пропущенными значениями! Чтобы заменить пропущенные значения, используйте fill_null().*

Пример:
```
df = pl.DataFrame(
    {
        "a": [1.5, 2, float("NaN"), 4],
        "b": [0.5, 4, float("NaN"), 13],
    }
)
df.fill_nan(99)
shape: (4, 2)
┌──────┬──────┐
│ a    ┆ b    │
│ ---  ┆ ---  │
│ f64  ┆ f64  │
╞══════╪══════╡
│ 1.5  ┆ 0.5  │
│ 2.0  ┆ 4.0  │
│ 99.0 ┆ 99.0 │
│ 4.0  ┆ 13.0 │
└──────┴──────┘
```
### **fill_null(**

    value: Any | None = None, 
    strategy: FillNullStrategy | None = None, 
    limit: int | None = None, 
    *, 
    matches_supertype: bool = True
) → DataFrame

Заполните нулевые значения, используя указанное значение или стратегию.

**Параметры:**

`value` Значение, используемое для заполнения нулевых значений.

`strategy {None, ‘forward’, ‘backward’, ‘min’, ‘max’, ‘mean’, ‘zero’, ‘one’} ` Стратегия, используемая для заполнения нулевых значений.

`limit` Количество последовательных нулевых значений, заполняемых при использовании стратегии ‘вперед’ или ‘назад’.

`matches_supertype` Заполните все соответствующие супертипу значения заполнения.

Возвращает: Фрейм данных, в котором нет значений, заменен стратегией заполнения.

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 2, None, 4],
        "b": [0.5, 4, None, 13],
    }
)
df.fill_null(99)
shape: (4, 2)
┌─────┬──────┐
│ a   ┆ b    │
│ --- ┆ ---  │
│ i64 ┆ f64  │
╞═════╪══════╡
│ 1   ┆ 0.5  │
│ 2   ┆ 4.0  │
│ 99  ┆ 99.0 │
│ 4   ┆ 13.0 │
└─────┴──────┘
df.fill_null(strategy="forward")
shape: (4, 2)
┌─────┬──────┐
│ a   ┆ b    │
│ --- ┆ ---  │
│ i64 ┆ f64  │
╞═════╪══════╡
│ 1   ┆ 0.5  │
│ 2   ┆ 4.0  │
│ 2   ┆ 4.0  │
│ 4   ┆ 13.0 │
└─────┴──────┘
df.fill_null(strategy="max")
shape: (4, 2)
┌─────┬──────┐
│ a   ┆ b    │
│ --- ┆ ---  │
│ i64 ┆ f64  │
╞═════╪══════╡
│ 1   ┆ 0.5  │
│ 2   ┆ 4.0  │
│ 4   ┆ 13.0 │
│ 4   ┆ 13.0 │
└─────┴──────┘
df.fill_null(strategy="zero")
shape: (4, 2)
┌─────┬──────┐
│ a   ┆ b    │
│ --- ┆ ---  │
│ i64 ┆ f64  │
╞═════╪══════╡
│ 1   ┆ 0.5  │
│ 2   ┆ 4.0  │
│ 0   ┆ 0.0  │
│ 4   ┆ 13.0 │
└─────┴──────┘
```
### **filter(**

    predicate: Expr | str | Series | list[bool] | 
    np.ndarray[Any, Any] | bool
) → DataFrame

Фильтруйте строки во фрейме данных на основе выражения предиката.

**Параметры:**

`predicate`Выражение, которое преобразуется в логический ряд.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
```
Фильтровать при одном условии:
```
df.filter(pl.col("foo") < 3)
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ a   │
│ 2   ┆ 7   ┆ b   │
└─────┴─────┴─────┘
```
Фильтровать по нескольким условиям:
```
df.filter((pl.col("foo") < 3) & (pl.col("ham") == "a"))
shape: (1, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ a   │
└─────┴─────┴─────┘
```
Фильтровать по условию ИЛИ:
```
df.filter((pl.col("foo") == 1) | (pl.col("ham") == "c"))
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ a   │
│ 3   ┆ 8   ┆ c   │
└─────┴─────┴─────┘
```
### **find_idx_by_name(**

    name: str
) → int

Найдите индекс столбца по имени.

**Параметры:**

`name` Название столбца, который нужно найти.

Пример:
```
df = pl.DataFrame(
    {"foo": [1, 2, 3], "bar": [6, 7, 8], "ham": ["a", "b", "c"]}
)
df.find_idx_by_name("ham")
2
```
### **fold(**

    operation: Callable[[Series, Series], Series]
) → Series

Примените горизонтальное уменьшение к фрейму данных.

Это может быть использовано для эффективного определения агрегаций на уровне строк и может быть применено к любому типу данных, который может быть суперкастирован (приведен к аналогичному родительскому типу).

Примером правил supercast при применении арифметической операции к двум типам данных являются, например:

`Int8 + Utf8 = Utf8 Float32 + Int64 = Float32 Float32 + Float64 = Float64`

**Параметры:**

`operation` функция, которая принимает две серии и возвращает одну серию.

Пример:

Операция горизонтального суммирования:
```
df = pl.DataFrame(
    {
        "a": [2, 1, 3],
        "b": [1, 2, 3],
        "c": [1.0, 2.0, 3.0],
    }
)
df.fold(lambda s1, s2: s1 + s2)
shape: (3,)
Series: 'a' [f64]
[
    4.0
    5.0
    9.0
]
```
Горизонтальная минимальная операция:

```
df = pl.DataFrame({"a": [2, 1, 3], "b": [1, 2, 3], "c": [1.0, 2.0, 3.0]})
df.fold(lambda s1, s2: s1.zip_with(s1 < s2, s2))
shape: (3,)
Series: 'a' [f64]
[
    1.0
    1.0
    3.0
]
```
Горизонтальная конкатенация строк:
```
df = pl.DataFrame(
    {
        "a": ["foo", "bar", 2],
        "b": [1, 2, 3],
        "c": [1.0, 2.0, 3.0],
    }
)
df.fold(lambda s1, s2: s1 + s2)
shape: (3,)
Series: 'a' [str]
[
    "foo11.0"
    "bar22.0"
    null
]
```
Горизонтальное логическое значение or, аналогичное строковому `.any()`:
```
df = pl.DataFrame(
    {
        "a": [False, False, True],
        "b": [False, True, False],
    }
)
df.fold(lambda s1, s2: s1 | s2)
shape: (3,)
Series: 'a' [bool]
[
        false
        true
        true
]
```
### **frame_equal(**

    other: DataFrame, 
    *, 
    null_equal: bool = True
) → bool

Проверьте, равен ли фрейм данных другому.

**Параметры:**

`other` Фрейм данных для сравнения.

`null_equal` Рассматривайте нулевые значения как равные.

Пример:
```
df1 = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
df2 = pl.DataFrame(
    {
        "foo": [3, 2, 1],
        "bar": [8.0, 7.0, 6.0],
        "ham": ["c", "b", "a"],
    }
)
df1.frame_equal(df1)
True
df1.frame_equal(df2)
False
```
### **get_column(**

    name: str
) → Series

Получите один столбец в виде серии по имени.

**Параметры:**

`name` *str* Имя столбца для извлечения.

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
df.get_column("foo")
shape: (3,)
Series: 'foo' [i64]
[
        1
        2
        3
]
```
### **get_columns(**
) → list[Series]

Получите фрейм данных в виде списка серий.

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
df.get_columns()
[shape: (3,)
Series: 'foo' [i64]
[
        1
        2
        3
], shape: (3,)
Series: 'bar' [i64]
[
        4
        5
        6
]]
```
```
df = pl.DataFrame(
    {
        "a": [1, 2, 3, 4],
        "b": [0.5, 4, 10, 13],
        "c": [True, True, False, True],
    }
)
df.get_columns()
[shape: (4,)
Series: 'a' [i64]
[
    1
    2
    3
    4
], shape: (4,)
Series: 'b' [f64]
[
    0.5
    4.0
    10.0
    13.0
], shape: (4,)
Series: 'c' [bool]
[
    true
    true
    false
    true
]]
```
### **glimpse(**
    *, 
    return_as_string: Literal[False]
) → None
**glimpse(**
    *, 
    return_as_string: Literal[True]
) → str

Возвращает плотный предварительный просмотр фрейма данных.

Форматирование выполняется по одной строке на столбец, поэтому широкие фреймы данных отображаются хорошо. В каждой строке будет указано имя столбца, тип данных и первые несколько значений.

**Параметры:**

`return_as_string` Если True, возвращайте в виде строки, а не выводите в стандартный вывод.

Пример:
```
from datetime import date
df = pl.DataFrame(
    {
        "a": [1.0, 2.8, 3.0],
        "b": [4, 5, None],
        "c": [True, False, True],
        "d": [None, "b", "c"],
        "e": ["usd", "eur", None],
        "f": [date(2020, 1, 1), date(2021, 1, 2), date(2022, 1, 1)],
    }
)
df.glimpse()
Rows: 3
Columns: 6
$ a  <f64> 1.0, 2.8, 3.0
$ b  <i64> 4, 5, None
$ c <bool> True, False, True
$ d  <str> None, b, c
$ e  <str> usd, eur, None
$ f <date> 2020-01-01, 2021-01-02, 2022-01-01
```
### **groupby(**
    
    by: IntoExpr | Iterable[IntoExpr], 
    *more_by: IntoExpr, 
    maintain_order: bool = False
) → GroupBy

Создайте группу по операции.

**Параметры:**

`by` Столбец (столбцы) для group by. Принимает ввод выражения. Строки анализируются как имена столбцов.

`*more_by` Дополнительные столбцы для группировки, указанные в качестве позиционных аргументов.

`maintain_order` Убедитесь, что порядок расположения групп соответствует входным данным. Это медленнее, чем группировка по умолчанию. Установка значения True блокирует возможность запуска на движке потоковой передачи.

Пример:

Сгруппируйте по одному столбцу и вызовите agg, чтобы вычислить сгруппированную сумму другого столбца.
```
df = pl.DataFrame(
    {
        "a": ["a", "b", "a", "b", "c"],
        "b": [1, 2, 1, 3, 3],
        "c": [5, 4, 3, 2, 1],
    }
)
df.groupby("a").agg(pl.col("b").sum())  
shape: (3, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ a   ┆ 2   │
│ b   ┆ 5   │
│ c   ┆ 3   │
└─────┴─────┘
```
Установите `maintain_order=True`, чтобы убедиться, что порядок групп соответствует входным данным.
```
df.groupby("a", maintain_order=True).agg(pl.col("c"))
shape: (3, 2)
┌─────┬───────────┐
│ a   ┆ c         │
│ --- ┆ ---       │
│ str ┆ list[i64] │
╞═════╪═══════════╡
│ a   ┆ [5, 3]    │
│ b   ┆ [4, 2]    │
│ c   ┆ [1]       │
└─────┴───────────┘
```
Сгруппируйте по нескольким столбцам, передав список имен столбцов.
```
df.groupby(["a", "b"]).agg(pl.max("c"))  
shape: (4, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ b   ┆ 2   ┆ 4   │
│ b   ┆ 3   ┆ 2   │
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘
```
Или используйте позиционные аргументы для группировки по нескольким столбцам таким же образом. Также принимаются выражения.
```
df.groupby("a", pl.col("b") // 2).agg(pl.col("c").mean())  
shape: (3, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ f64 │
╞═════╪═════╪═════╡
│ a   ┆ 0   ┆ 4.0 │
│ b   ┆ 1   ┆ 3.0 │
│ c   ┆ 1   ┆ 1.0 │
└─────┴─────┴─────┘
```
Объект GroupBy, возвращаемый этим методом, является итеративным, возвращая имя и данные каждой группы.
```
for name, data in df.groupby("a"):  
    print(name)
    print(data)

a
shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ a   ┆ 1   ┆ 3   │
└─────┴─────┴─────┘
b
shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 2   ┆ 4   │
│ b   ┆ 3   ┆ 2   │
└─────┴─────┴─────┘
c
shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘
```
### **groupby_dynamic(**

    index_column: IntoExpr, 
    *, 
    every: str | timedelta, 
    period: str | timedelta | None = None, 
    offset: str | timedelta | None = None, 
    truncate: bool = True, 
    include_boundaries: bool = False, 
    closed: ClosedInterval = 'left', 
    by: IntoExpr | Iterable[IntoExpr] | None = None, 
    start_by: StartBy = 'window', 
    check_sorted: bool = True
) → DynamicGroupBy

Группируйте на основе значения времени (или значения индекса типа Int32, Int64).

Вычисляются временные окна, и строкам присваиваются значения для окон. Отличие от обычной группы в том, что строка может быть членом нескольких групп. Окно time/index можно рассматривать как переходящее окно, размер которого определяется датами/временем /значениями вместо интервалов во фрейме данных.

Окно определяется с помощью:

`every`: интервал окна

`period`: длина окна

`offset`: смещение окна

Аргументы `every`, `period` и `offset` создаются с помощью следующего языка строк:

1ns (1 nanosecond)

1us (1 microsecond)

1ms (1 millisecond)

1s (1 second)

1m (1 minute)

1h (1 hour)

1d (1 day)

1w (1 week)

1mo (1 calendar month)

1q (1 quarter)

1y (1 calendar year)

1i (1 index count)

Или объедините их: `“3d12h4m25s”` # 3 дня, 12 часов, 4 минуты и 25 секунд

Суффикс  `“_saturating”`, указывающий на то, что даты, слишком большие для своего месяца, должны насыщаться на самую большую дату (например, 2022-02-29 -> 2022-02-28) вместо ошибки.

В случае `groupby_dynamic` для целочисленного столбца окна определяются с помощью:

“1i” # length 1

“10i” # length 10

Предупреждение

Столбец индекса должен быть отсортирован в порядке возрастания.

**Параметры:**

`index_column` Столбец, используемый для группировки на основе временного окна. Часто для ввода даты/Datetime этот столбец необходимо отсортировать в порядке возрастания. Если нет, то вывод не будет иметь смысла.

В случае динамической группировки по индексам, dtype должен быть одним из {Int32, Int64}. Обратите внимание, что Int32 временно преобразуется в Int64, поэтому, если важна производительность, используйте столбец Int64.

`every` интервал окна

`period` длина окна, если нет, то она равна ‘every’

`offset` смещение окна, если None и точка равны None, будет равно отрицательному значению каждый раз

`truncate` усеките значение времени до нижней границы окна

`include_boundaries` Добавьте нижнюю и верхнюю границы окна в столбцы ”_lower_bound" и “_upper_bound”. Это повлияет на производительность, поскольку ее сложнее распараллелить

`closed{‘left’, ‘right’, ‘both’, ‘none’}` Определите, какие стороны временного интервала являются закрытыми (включительно).

`by` Также сгруппируйте по этому столбцу/этим столбцам

`start_by{‘window’, ‘datapoint’, ‘monday’, ‘tuesday’, ‘wednesday’, ‘thursday’, ‘friday’, ‘saturday’, ‘sunday’}` Стратегия определения начала первого окна с помощью.

‘window’: Усеките начало окна с помощью аргумента ‘every’.

‘datapoint’: Начните с первой встреченной точки данных.

‘monday’: Запустите окно в понедельник перед первой точкой данных.

‘tuesday’: Запустите окно во вторник, предшествующий первой точке данных.
…

‘sunday’: Запустите окно в воскресенье перед первой точкой данных.

`check_sorted` Когда задан аргумент by, polars не может проверить сортировку по метаданным и должен выполнить полное сканирование столбца индекса, чтобы убедиться, что данные отсортированы. Это дорого стоит. Если вы уверены, что данные внутри групп по отсортированы, вы можете установить для этого значение False. Неправильное выполнение этого требования приведет к неправильному выводу

Возвращает:
DynamicGroupBy
Объект, на который вы можете вызвать .agg для агрегирования по группам, результат которого будет отсортирован по index_column (но обратите внимание, что если передается по столбцам, он будет отсортирован только внутри каждой группы по).

Пример:
```
from datetime import datetime
# создайте пример фрейма данных
df = pl.DataFrame(
    {
        "time": pl.date_range(
            start=datetime(2021, 12, 16),
            end=datetime(2021, 12, 16, 3),
            interval="30m",
            eager=True,
        ),
        "n": range(7),
    }
)
df
shape: (7, 2)
┌─────────────────────┬─────┐
│ time                ┆ n   │
│ ---                 ┆ --- │
│ datetime[μs]        ┆ i64 │
╞═════════════════════╪═════╡
│ 2021-12-16 00:00:00 ┆ 0   │
│ 2021-12-16 00:30:00 ┆ 1   │
│ 2021-12-16 01:00:00 ┆ 2   │
│ 2021-12-16 01:30:00 ┆ 3   │
│ 2021-12-16 02:00:00 ┆ 4   │
│ 2021-12-16 02:30:00 ┆ 5   │
│ 2021-12-16 03:00:00 ┆ 6   │
└─────────────────────┴─────┘
```
Группируйте по окнам на 1 час, начиная с 2021-12-16 00:00:00.
```
df.groupby_dynamic("time", every="1h", closed="right").agg(
    [
        pl.col("time").min().alias("time_min"),
        pl.col("time").max().alias("time_max"),
    ]
)
shape: (4, 3)
┌─────────────────────┬─────────────────────┬─────────────────────┐
│ time                ┆ time_min            ┆ time_max            │
│ ---                 ┆ ---                 ┆ ---                 │
│ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        │
╞═════════════════════╪═════════════════════╪═════════════════════╡
│ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 00:00:00 │
│ 2021-12-16 00:00:00 ┆ 2021-12-16 00:30:00 ┆ 2021-12-16 01:00:00 │
│ 2021-12-16 01:00:00 ┆ 2021-12-16 01:30:00 ┆ 2021-12-16 02:00:00 │
│ 2021-12-16 02:00:00 ┆ 2021-12-16 02:30:00 ┆ 2021-12-16 03:00:00 │
└─────────────────────┴─────────────────────┴─────────────────────┘
```
Границы окна также могут быть добавлены к результату агрегирования
```
df.groupby_dynamic(
    "time", every="1h", include_boundaries=True, closed="right"
).agg([pl.col("time").count().alias("time_count")])
shape: (4, 4)
┌─────────────────────┬─────────────────────┬─────────────────────┬────────────┐
│ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ time_count │
│ ---                 ┆ ---                 ┆ ---                 ┆ ---        │
│ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ u32        │
╞═════════════════════╪═════════════════════╪═════════════════════╪════════════╡
│ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-15 23:00:00 ┆ 1          │
│ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ 2          │
│ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ 2          │
│ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ 2          │
└─────────────────────┴─────────────────────┴─────────────────────┴────────────┘
```
Когда `closed=”left”`, не следует включать правый конец интервала `[lower_bound, upper_bound)`
```
df.groupby_dynamic("time", every="1h", closed="left").agg(
    [
        pl.col("time").count().alias("time_count"),
        pl.col("time").alias("time_agg_list"),
    ]
)
shape: (4, 3)
┌─────────────────────┬────────────┬───────────────────────────────────┐
│ time                ┆ time_count ┆ time_agg_list                     │
│ ---                 ┆ ---        ┆ ---                               │
│ datetime[μs]        ┆ u32        ┆ list[datetime[μs]]                │
╞═════════════════════╪════════════╪═══════════════════════════════════╡
│ 2021-12-16 00:00:00 ┆ 2          ┆ [2021-12-16 00:00:00, 2021-12-16… │
│ 2021-12-16 01:00:00 ┆ 2          ┆ [2021-12-16 01:00:00, 2021-12-16… │
│ 2021-12-16 02:00:00 ┆ 2          ┆ [2021-12-16 02:00:00, 2021-12-16… │
│ 2021-12-16 03:00:00 ┆ 1          ┆ [2021-12-16 03:00:00]             │
└─────────────────────┴────────────┴───────────────────────────────────┘
```
Когда `closed=”both”`, значения времени на границах окна принадлежат к 2 группам.
```
df.groupby_dynamic("time", every="1h", closed="both").agg(
    [pl.col("time").count().alias("time_count")]
)
shape: (5, 2)
┌─────────────────────┬────────────┐
│ time                ┆ time_count │
│ ---                 ┆ ---        │
│ datetime[μs]        ┆ u32        │
╞═════════════════════╪════════════╡
│ 2021-12-15 23:00:00 ┆ 1          │
│ 2021-12-16 00:00:00 ┆ 3          │
│ 2021-12-16 01:00:00 ┆ 3          │
│ 2021-12-16 02:00:00 ┆ 3          │
│ 2021-12-16 03:00:00 ┆ 1          │
└─────────────────────┴────────────┘
```
Динамическая группировка по ключам также может быть объединена с группировкой по обычным ключам
```
df = pl.DataFrame(
    {
        "time": pl.date_range(
            start=datetime(2021, 12, 16),
            end=datetime(2021, 12, 16, 3),
            interval="30m",
            eager=True,
        ),
        "groups": ["a", "a", "a", "b", "b", "a", "a"],
    }
)
df
shape: (7, 2)
┌─────────────────────┬────────┐
│ time                ┆ groups │
│ ---                 ┆ ---    │
│ datetime[μs]        ┆ str    │
╞═════════════════════╪════════╡
│ 2021-12-16 00:00:00 ┆ a      │
│ 2021-12-16 00:30:00 ┆ a      │
│ 2021-12-16 01:00:00 ┆ a      │
│ 2021-12-16 01:30:00 ┆ b      │
│ 2021-12-16 02:00:00 ┆ b      │
│ 2021-12-16 02:30:00 ┆ a      │
│ 2021-12-16 03:00:00 ┆ a      │
└─────────────────────┴────────┘
df.groupby_dynamic(
    "time",
    every="1h",
    closed="both",
    by="groups",
    include_boundaries=True,
).agg([pl.col("time").count().alias("time_count")])
shape: (7, 5)
┌────────┬─────────────────────┬─────────────────────┬─────────────────────┬────────────┐
│ groups ┆ _lower_boundary     ┆ _upper_boundary     ┆ time                ┆ time_count │
│ ---    ┆ ---                 ┆ ---                 ┆ ---                 ┆ ---        │
│ str    ┆ datetime[μs]        ┆ datetime[μs]        ┆ datetime[μs]        ┆ u32        │
╞════════╪═════════════════════╪═════════════════════╪═════════════════════╪════════════╡
│ a      ┆ 2021-12-15 23:00:00 ┆ 2021-12-16 00:00:00 ┆ 2021-12-15 23:00:00 ┆ 1          │
│ a      ┆ 2021-12-16 00:00:00 ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 00:00:00 ┆ 3          │
│ a      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ 1          │
│ a      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ 2          │
│ a      ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 04:00:00 ┆ 2021-12-16 03:00:00 ┆ 1          │
│ b      ┆ 2021-12-16 01:00:00 ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 01:00:00 ┆ 2          │
│ b      ┆ 2021-12-16 02:00:00 ┆ 2021-12-16 03:00:00 ┆ 2021-12-16 02:00:00 ┆ 1          │
└────────┴─────────────────────┴─────────────────────┴─────────────────────┴────────────┘
```
Динамическая группировка по столбцу индекса
```
df = pl.DataFrame(
    {
        "idx": pl.arange(0, 6, eager=True),
        "A": ["A", "A", "B", "B", "B", "C"],
    }
)
(
    df.groupby_dynamic(
        "idx",
        every="2i",
        period="3i",
        include_boundaries=True,
        closed="right",
    ).agg(pl.col("A").alias("A_agg_list"))
)
shape: (3, 4)
┌─────────────────┬─────────────────┬─────┬─────────────────┐
│ _lower_boundary ┆ _upper_boundary ┆ idx ┆ A_agg_list      │
│ ---             ┆ ---             ┆ --- ┆ ---             │
│ i64             ┆ i64             ┆ i64 ┆ list[str]       │
╞═════════════════╪═════════════════╪═════╪═════════════════╡
│ 0               ┆ 3               ┆ 0   ┆ ["A", "B", "B"] │
│ 2               ┆ 5               ┆ 2   ┆ ["B", "B", "C"] │
│ 4               ┆ 7               ┆ 4   ┆ ["C"]           │
└─────────────────┴─────────────────┴─────┴─────────────────┘
```
### **groupby_rolling(**

    index_column: IntoExpr, 
    *, 
    period: str | timedelta, 
    offset: str | timedelta | None = None, 
    closed: ClosedInterval = 'right', 
    by: IntoExpr | Iterable[IntoExpr] | None = None, 
    check_sorted: bool = True
) → RollingGroupBy

Создавайте переходящие группы на основе столбца time, Int32 или Int64.

В отличие от `dynamic_groupby`, окна теперь определяются отдельными значениями и не имеют постоянных интервалов. Для постоянных интервалов используйте `groupby_dynamic`.

Если у вас есть временной ряд `<t_0, t_1, ..., t_n>`, то по умолчанию созданные окна будут

(t_0 - period, t_0]

(t_1 - period, t_1]

…

(t_n - period, t_n]

Аргументы `period` и `offset` создаются либо из `timedelta`, либо с помощью следующего строкового языка:

1ns (1 nanosecond)

1us (1 microsecond)

1ms (1 millisecond)

1s (1 second)

1m (1 minute)

1h (1 hour)

1d (1 day)

1w (1 week)

1mo (1 calendar month)

1q (1 calendar quarter)

1y (1 calendar year)

1i (1 index count)

Или объедините их: `“3d12h4m25s”` # 3 дня, 12 часов, 4 минуты и 25 секунд

Суффикс  `“_saturating”`, указывающий на то, что даты, слишком большие для своего месяца, должны насыщаться на самую большую дату (например, 2022-02-29 -> 2022-02-28) вместо ошибки.

В случае `groupby_rolling` для целочисленного столбца окна определяются с помощью:

“1i” # length 1

“10i” # length 10


**Параметры:**

`index_column` Столбец, используемый для группировки на основе временного окна. Часто для ввода даты/Datetime этот столбец необходимо отсортировать в порядке возрастания. Если нет, то вывод не будет иметь смысла.

В случае скользящей группировки по индексам, `dtype` должен быть одним из {Int32, Int64}. Обратите внимание, что Int32 временно преобразуется в Int64, поэтому, если важна производительность, используйте столбец Int64.

`period` длина окна

`offset` смещение окна. Значение по умолчанию -точка

`closed{‘right’, ‘left’, ‘both’, ‘none’}` Определите, какие стороны временного интервала являются закрытыми (включительно).

`by` Также группируется по этому столбцу/этим столбцам

`check_sorted` Когда задан аргумент by, polars не может проверить сортировку по метаданным и должен выполнить полное сканирование столбца индекса, чтобы убедиться, что данные отсортированы. Это дорого стоит. Если вы уверены, что данные внутри групп по отсортированы, вы можете установить для этого значение False. Неправильное выполнение этого требования приведет к неправильному выводу

Возвращает: RollingGroupBy
Объект, на который вы можете вызвать .agg для агрегирования по группам, результат которого будет отсортирован по index_column (но обратите внимание, что если передаются столбцы by, он будет отсортирован только внутри каждой группы by).

Пример:
```
dates = [
    "2020-01-01 13:45:48",
    "2020-01-01 16:42:13",
    "2020-01-01 16:45:09",
    "2020-01-02 18:12:48",
    "2020-01-03 19:45:32",
    "2020-01-08 23:16:43",
]
df = pl.DataFrame({"dt": dates, "a": [3, 7, 5, 9, 2, 1]}).with_columns(
    pl.col("dt").str.strptime(pl.Datetime).set_sorted()
)
out = df.groupby_rolling(index_column="dt", period="2d").agg(
    [
        pl.sum("a").alias("sum_a"),
        pl.min("a").alias("min_a"),
        pl.max("a").alias("max_a"),
    ]
)
assert out["sum_a"].to_list() == [3, 10, 15, 24, 11, 1]
assert out["max_a"].to_list() == [3, 7, 7, 9, 9, 1]
assert out["min_a"].to_list() == [3, 3, 3, 3, 2, 1]
out
shape: (6, 4)
┌─────────────────────┬───────┬───────┬───────┐
│ dt                  ┆ sum_a ┆ min_a ┆ max_a │
│ ---                 ┆ ---   ┆ ---   ┆ ---   │
│ datetime[μs]        ┆ i64   ┆ i64   ┆ i64   │
╞═════════════════════╪═══════╪═══════╪═══════╡
│ 2020-01-01 13:45:48 ┆ 3     ┆ 3     ┆ 3     │
│ 2020-01-01 16:42:13 ┆ 10    ┆ 3     ┆ 7     │
│ 2020-01-01 16:45:09 ┆ 15    ┆ 3     ┆ 7     │
│ 2020-01-02 18:12:48 ┆ 24    ┆ 3     ┆ 9     │
│ 2020-01-03 19:45:32 ┆ 11    ┆ 2     ┆ 9     │
│ 2020-01-08 23:16:43 ┆ 1     ┆ 1     ┆ 1     │
└─────────────────────┴───────┴───────┴───────┘
```
### **hash_rows(**

    seed: int = 0, 
    seed_1: int | None = None, 
    seed_2: int | None = None, 
    seed_3: int | None = None
) → Series

Хэшируйте и объединяйте строки в этом фрейме данных.

Хэш-значение имеет тип UInt64.

**Параметры:**

`seed`
Случайный начальный параметр. Значение по умолчанию равно 0.

`seed_1`
Случайный начальный параметр. По умолчанию используется начальное значение, если оно не задано.

`seed_2`
Случайный начальный параметр. По умолчанию используется начальное значение, если оно не задано.

`seed_3`
Случайный начальный параметр. По умолчанию используется начальное значение, если оно не задано.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, None, 3, 4],
        "ham": ["a", "b", None, "d"],
    }
)
df.hash_rows(seed=42)  
shape: (4,)
Series: '' [u64]
[
    10783150408545073287
    1438741209321515184
    10047419486152048166
    2047317070637311557
]
```
### **head(**
    n: int = 5
) → Self

Получите первые n строк.

**Параметры:**

`n` Количество возвращаемых строк. Если передано отрицательное значение, верните все строки, кроме последней abs(n).

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3, 4, 5],
        "bar": [6, 7, 8, 9, 10],
        "ham": ["a", "b", "c", "d", "e"],
    }
)
df.head(3)
shape: (3, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ a   │
│ 2   ┆ 7   ┆ b   │
│ 3   ┆ 8   ┆ c   │
└─────┴─────┴─────┘
```
Передайте отрицательное значение, чтобы получить все строки, кроме последней abs(n).
```
df.head(-3)
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ a   │
│ 2   ┆ 7   ┆ b   │
└─────┴─────┴─────┘
```
свойство **property height**: *int*

Получите высоту фрейма данных.

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3, 4, 5]})
df.height
5
```
### **hstack(**

    columns: list[Series] | DataFrame, 
    *, 
    in_place: bool = False
) → Self

Верните новый фрейм данных, увеличенный горизонтально путем добавления к нему нескольких рядов.

**Параметры:**

`columns` Series to stack.

`in_place` Modify in place.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
x = pl.Series("apple", [10, 20, 30])
df.hstack([x])
shape: (3, 4)
┌─────┬─────┬─────┬───────┐
│ foo ┆ bar ┆ ham ┆ apple │
│ --- ┆ --- ┆ --- ┆ ---   │
│ i64 ┆ i64 ┆ str ┆ i64   │
╞═════╪═════╪═════╪═══════╡
│ 1   ┆ 6   ┆ a   ┆ 10    │
│ 2   ┆ 7   ┆ b   ┆ 20    │
│ 3   ┆ 8   ┆ c   ┆ 30    │
└─────┴─────┴─────┴───────┘
```
### **insert_at_idx(**
    
    index: int, 
    series: Series
) → Self

Вставьте серию с определенным индексом столбца. Эта операция уже проведена.

**Параметры:**

`index` Столбец для вставки нового столбца Series
`series` Series для вставки

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
s = pl.Series("baz", [97, 98, 99])
df.insert_at_idx(1, s)
shape: (3, 3)
┌─────┬─────┬─────┐
│ foo ┆ baz ┆ bar │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ 1   ┆ 97  ┆ 4   │
│ 2   ┆ 98  ┆ 5   │
│ 3   ┆ 99  ┆ 6   │
└─────┴─────┴─────┘
df = pl.DataFrame(
    {
        "a": [1, 2, 3, 4],
        "b": [0.5, 4, 10, 13],
        "c": [True, True, False, True],
    }
)
s = pl.Series("d", [-2.5, 15, 20.5, 0])
df.insert_at_idx(3, s)
shape: (4, 4)
┌─────┬──────┬───────┬──────┐
│ a   ┆ b    ┆ c     ┆ d    │
│ --- ┆ ---  ┆ ---   ┆ ---  │
│ i64 ┆ f64  ┆ bool  ┆ f64  │
╞═════╪══════╪═══════╪══════╡
│ 1   ┆ 0.5  ┆ true  ┆ -2.5 │
│ 2   ┆ 4.0  ┆ true  ┆ 15.0 │
│ 3   ┆ 10.0 ┆ false ┆ 20.5 │
│ 4   ┆ 13.0 ┆ true  ┆ 0.0  │
└─────┴──────┴───────┴──────┘
```
### **interpolate(**
) → DataFrame

Интерполируйте промежуточные значения. Метод интерполяции является линейным.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, None, 9, 10],
        "bar": [6, 7, 9, None],
        "baz": [1, None, None, 9],
    }
)
df.interpolate()
shape: (4, 3)
┌─────┬──────┬─────┐
│ foo ┆ bar  ┆ baz │
│ --- ┆ ---  ┆ --- │
│ i64 ┆ i64  ┆ i64 │
╞═════╪══════╪═════╡
│ 1   ┆ 6    ┆ 1   │
│ 5   ┆ 7    ┆ 3   │
│ 9   ┆ 9    ┆ 6   │
│ 10  ┆ null ┆ 9   │
└─────┴──────┴─────┘
```
### **is_duplicated(**
) → Series

Получите маску всех дублированных строк в этом фрейме данных.

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 2, 3, 1],
        "b": ["x", "y", "z", "x"],
    }
)
df.is_duplicated()
shape: (4,)
Series: '' [bool]
[
        true
        false
        false
        true
]
```
Эту маску можно использовать для визуализации дублированных линий следующим образом:
```
df.filter(df.is_duplicated())
shape: (2, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ str │
╞═════╪═════╡
│ 1   ┆ x   │
│ 1   ┆ x   │
└─────┴─────┘
```
### **is_empty(**
) → bool

Проверьте, пуст ли фрейм данных.

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
df.is_empty()
False
df.filter(pl.col("foo") > 99).is_empty()
True
```
## **is_unique(**
) → Series

Получите маску всех уникальных строк в этом фрейме данных.

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 2, 3, 1],
        "b": ["x", "y", "z", "x"],
    }
)
df.is_unique()
shape: (4,)
Series: '' [bool]
[
        false
        true
        true
        false
]
```
Эту маску можно использовать для визуализации уникальных линий, подобных этой:
```
df.filter(df.is_unique())
shape: (2, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ str │
╞═════╪═════╡
│ 2   ┆ y   │
│ 3   ┆ z   │
└─────┴─────┘
```
### **item(**
    
    row: int | None = None, 
    column: int | str | None = None
) → Any

Верните фрейм данных в виде скаляра или верните элемент в заданной строке/столбце.

**Параметры:**

`row` опционально индекс строки

`column` опционально индекс или имя столбца.

Примечание:

Если `row/col` не указаны, это эквивалентно `df[0,0]`, с проверкой, что форма равна `(1,1)`. С `row/col` это эквивалентно `df[row,col]`.

Пример:
```
df = pl.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
df.select((pl.col("a") * pl.col("b")).sum()).item()
32
df.item(1, 1)
5
df.item(2, "b")
6
```
### **iter_rows(**
    
    *, 
    named: Literal[False] = False, 
    buffer_size: int = 500
) → Iterator[tuple[Any, ...]]

**iter_rows(**
    
    *, 
    named: Literal[True], 
    buffer_size: int = 500
) → Iterator[dict[str, Any]]

Возвращает итератор по фрейму данных из строк собственных значений python.

**Параметры:**

`named` Возвращайте словари вместо кортежей. Словари представляют собой сопоставление имени столбца со значением строки. Это дороже, чем возврат обычного кортежа, но позволяет получить доступ к значениям по имени столбца.

`buffer_size` Определяет количество строк, которые буферизуются внутри во время итерации по данным; вы должны изменять это только в очень специфических случаях, когда определено, что значение по умолчанию не подходит для вашего шаблона доступа, поскольку ускорение от использования буфера является значительным (~ 2-4 раза). Установка этого значения равным нулю отключает буферизацию строк (не рекомендуется).

Возвращает:
Итератор кортежей (по умолчанию) или словарей (если они именованы) значений строк python.

Предупреждение

Итерация по строкам не является оптимальной, поскольку базовые данные хранятся в столбчатой форме; там, где это возможно, отдавайте предпочтение экспорту с помощью одного из специальных методов экспорта/вывода, который работает со столбчатыми данными.

**Примечание:**

Если у вас есть временные значения с точностью до ns, вы должны знать, что python изначально поддерживает только точность до us; если это имеет значение в вашем случае использования, вам следует экспортировать в другой формат.

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 3, 5],
        "b": [2, 4, 6],
    }
)
[row[0] for row in df.iter_rows()]
[1, 3, 5]
[row["b"] for row in df.iter_rows(named=True)]
[2, 4, 6]
```
### **iter_slices(**

    n_rows: int = 10000
) → Iterator[DataFrame]

Возвращает некопирующий итератор фрагментов по базовому фрейму данных.

**Параметры:**

`n_rows` Определяет количество строк, содержащихся в каждом фрагменте фрейма данных.

Пример:
```
from datetime import date
df = pl.DataFrame(
    data={
        "a": range(17_500),
        "b": date(2023, 1, 1),
        "c": "klmnoopqrstuvwxyz",
    },
    schema_overrides={"a": pl.Int32},
)
for idx, frame in enumerate(df.iter_slices()):
    print(f"{type(frame).__name__}:[{idx}]:{len(frame)}")

DataFrame:[0]:10000
DataFrame:[1]:7500
```
Использование iter_slices - это эффективный способ выполнения итерации по фрагментам данных и любым поддерживаемым типам экспорта/преобразования кадров; например, в виде пакетов записей:
```
for frame in df.iter_slices(n_rows=15_000):
    record_batch = frame.to_arrow().to_batches()[0]
    print(record_batch, "\n<< ", len(record_batch))

pyarrow.RecordBatch
a: int32
b: date32[day]
c: large_string
<< 15000
pyarrow.RecordBatch
a: int32
b: date32[day]
c: large_string
<< 2500
```
### **join(**

    other: DataFrame, 
    on: str | Expr | Sequence[str | Expr] | None = None, 
    how: JoinStrategy = 'inner', 
    *, 
    left_on: str | Expr | Sequence[str | Expr] | None = None, 
    right_on: str | Expr | Sequence[str | Expr] | None = None, 
    suffix: str = '_right', 
    validate: str = 'm:m'
) → DataFrame

Присоединяйтесь в SQL-подобном режиме.

**Параметры:**

`other` Фрейм данных, к которому нужно присоединиться.

`on` Имена объединяемых столбцов в обоих фреймах данных.

`how{‘inner’, ‘left’, ‘outer’, ‘semi’, ‘anti’, ‘cross’}` Присоединяйтесь к стратегии.

`left_on` Название(названия) левого столбца (столбцов) объединения.

`right_on` Имя(имена) столбца(столбцов) правого соединения.

`suffix` Суффикс для добавления к столбцам с повторяющимся именем.

`validate: {‘m:m’, ‘m:1’, ‘1:m’, ‘m:m’}` Проверяет, имеет ли соединение указанный тип.

`many_to_many` “m:m”: по умолчанию, не приводит к проверкам

`one_to_one` “1:1”: проверьте, уникальны ли ключи соединения как в левом, так и в правом наборах данных

`one_to_many` “1:m”: проверьте, уникальны ли ключи соединения в левом наборе данных

`many_to_one` “m:1”: проверьте, уникальны ли ключи соединения в нужном наборе данных

Примечание:

В настоящее время это не поддерживается движком потоковой передачи.

Это поддерживается только в том случае, если они объединены отдельными столбцами.

Возвращает: Объединенный фрейм данных

Примечание:

Для объединения столбцов с категориальными данными смотрите `pl.StringCache()`.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
other_df = pl.DataFrame(
    {
        "apple": ["x", "y", "z"],
        "ham": ["a", "b", "d"],
    }
)
df.join(other_df, on="ham")
shape: (2, 4)
┌─────┬─────┬─────┬───────┐
│ foo ┆ bar ┆ ham ┆ apple │
│ --- ┆ --- ┆ --- ┆ ---   │
│ i64 ┆ f64 ┆ str ┆ str   │
╞═════╪═════╪═════╪═══════╡
│ 1   ┆ 6.0 ┆ a   ┆ x     │
│ 2   ┆ 7.0 ┆ b   ┆ y     │
└─────┴─────┴─────┴───────┘
df.join(other_df, on="ham", how="outer")
shape: (4, 4)
┌──────┬──────┬─────┬───────┐
│ foo  ┆ bar  ┆ ham ┆ apple │
│ ---  ┆ ---  ┆ --- ┆ ---   │
│ i64  ┆ f64  ┆ str ┆ str   │
╞══════╪══════╪═════╪═══════╡
│ 1    ┆ 6.0  ┆ a   ┆ x     │
│ 2    ┆ 7.0  ┆ b   ┆ y     │
│ null ┆ null ┆ d   ┆ z     │
│ 3    ┆ 8.0  ┆ c   ┆ null  │
└──────┴──────┴─────┴───────┘
df.join(other_df, on="ham", how="left")
shape: (3, 4)
┌─────┬─────┬─────┬───────┐
│ foo ┆ bar ┆ ham ┆ apple │
│ --- ┆ --- ┆ --- ┆ ---   │
│ i64 ┆ f64 ┆ str ┆ str   │
╞═════╪═════╪═════╪═══════╡
│ 1   ┆ 6.0 ┆ a   ┆ x     │
│ 2   ┆ 7.0 ┆ b   ┆ y     │
│ 3   ┆ 8.0 ┆ c   ┆ null  │
└─────┴─────┴─────┴───────┘
df.join(other_df, on="ham", how="semi")
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6.0 ┆ a   │
│ 2   ┆ 7.0 ┆ b   │
└─────┴─────┴─────┘
df.join(other_df, on="ham", how="anti")
shape: (1, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 3   ┆ 8.0 ┆ c   │
└─────┴─────┴─────┘
```
### **join_asof(**

    other: DataFrame, 
    *, 
    left_on: str | None | Expr = None, 
    right_on: str | None | Expr = None, 
    on: str | None | Expr = None, 
    by_left: str | Sequence[str] | None = None, 
    by_right: str | Sequence[str] | None = None, 
    by: str | Sequence[str] | None = None, 
    strategy: AsofJoinStrategy = 'backward', 
    suffix: str = '_right', 
    tolerance: str | int | float | None = None, 
    allow_parallel: bool = True, 
    force_parallel: bool = False
) → DataFrame

Выполните соединение asof.

Это похоже на левое соединение, за исключением того, что мы сопоставляем по ближайшему ключу, а не по равным ключам.

Оба фрейма данных должны быть отсортированы по ключу asof_join.

Для каждой строки в левом фрейме данных:

При `“backward”` поиске выбирается последняя строка в правом фрейме данных, ключ `"on"` которой меньше или равен ключу левого фрейма.

При “forward” поиске выбирается первая строка в правом фрейме данных, ключ `"on"` которой больше или равен ключу левого фрейма.

При поиске `“nearest”` выбирается последняя строка в правом фрейме данных, значение которой ближе всего к ключу левого фрейма.

Значение по умолчанию - `“backward”`.

**Параметры:**

`other` Отложенный фрейм данных для объединения.

`left_on` Присоедините столбец к левому фрейму данных.

`right_on` Присоедините столбец к правому фрейму данных.

`on` Объедините столбец обоих фреймов данных. Если задано, то `left_on` и `right_on` должны быть равны `None`.

`by` присоединяйтесь к этим столбцам, прежде чем выполнять asof join

`by_left` присоединяйтесь к этим столбцам, прежде чем выполнять asof join

`by_right` присоединяйтесь к этим столбцам, прежде чем выполнять asof join

`strategy{‘backward’, ‘forward’, ‘nearest’}` Присоединяйтесь к стратегии.

`suffix` Суффикс для добавления к столбцам с повторяющимся именем.

`tolerance` Числовой допуск. Установив это значение, соединение будет выполнено только в том случае, если ближние клавиши находятся на этом расстоянии. Если соединение asof выполняется для столбцов типа dtype “Date”, “Datetime”, “Duration” или “Time”, используйте следующий строковый язык:

1ns (1 nanosecond)

1us (1 microsecond)

1ms (1 millisecond)

1s (1 second)

1m (1 minute)

1h (1 hour)

1d (1 day)

1w (1 week)

1mo (1 calendar month)

1q (1 calendar quarter)

1y (1 calendar year)

1i (1 index count)

Или объедините их: `“3d12h4m25s”` # 3 дня, 12 часов, 4 минуты и 25 секунд

Суффикс `“_saturating”`, указывающий на то, что даты, слишком большие для своего месяца, должны насыщаться на самую большую дату (например, 2022-02-29 -> 2022-02-28) вместо ошибки.

`allow_parallel` Разрешите физическому плану дополнительно оценивать вычисление обоих фреймов данных вплоть до объединения параллельно.

`force_parallel`Заставьте физический план оценивать вычисление обоих фреймов данных вплоть до объединения параллельно.

Пример:
```
from datetime import datetime
gdp = pl.DataFrame(
    {
        "date": [
            datetime(2016, 1, 1),
            datetime(2017, 1, 1),
            datetime(2018, 1, 1),
            datetime(2019, 1, 1),
        ],  # note record date: Jan 1st (sorted!)
        "gdp": [4164, 4411, 4566, 4696],
    }
).set_sorted("date")
population = pl.DataFrame(
    {
        "date": [
            datetime(2016, 5, 12),
            datetime(2017, 5, 12),
            datetime(2018, 5, 12),
            datetime(2019, 5, 12),
        ],  # note record date: May 12th (sorted!)
        "population": [82.19, 82.66, 83.12, 83.52],
    }
).set_sorted("date")
population.join_asof(gdp, on="date", strategy="backward")
shape: (4, 3)
┌─────────────────────┬────────────┬──────┐
│ date                ┆ population ┆ gdp  │
│ ---                 ┆ ---        ┆ ---  │
│ datetime[μs]        ┆ f64        ┆ i64  │
╞═════════════════════╪════════════╪══════╡
│ 2016-05-12 00:00:00 ┆ 82.19      ┆ 4164 │
│ 2017-05-12 00:00:00 ┆ 82.66      ┆ 4411 │
│ 2018-05-12 00:00:00 ┆ 83.12      ┆ 4566 │
│ 2019-05-12 00:00:00 ┆ 83.52      ┆ 4696 │
└─────────────────────┴────────────┴──────┘
```
### **lazy(**
) → LazyFrame

Запустите отложенный запрос с этого момента. Это возвращает объект отложенного фрейма.

Операции с LazyFrame не выполняются до тех пор, пока это не будет запрошено любым вызывающим:

`.fetch()`
(выполняется на небольшом количестве строк)

`.collect()`
(запуск со всеми данными)

`.describe_plan()`
(печать оптимизированного плана запроса)

`.describe_optimized_plan()`
(печать оптимизированного плана запроса)

`.show_graph()`
(показать (не)оптимизированный план запроса в виде графика graphviz)

Рекомендуется выполнять отложенные операции, поскольку они обеспечивают оптимизацию запросов и большее распараллеливание.

Возвращает: LazyFrame

Пример:
```
df = pl.DataFrame(
    {
        "a": [None, 2, 3, 4],
        "b": [0.5, None, 2.5, 13],
        "c": [True, True, False, None],
    }
)
df.lazy()  
<polars.LazyFrame object at ...>
```

### **limit(**
    n: int = 5
) → Self

Получите первые n строк.

Псевдоним для DataFrame.head().

**Параметры:**

`n` Number of rows to return. If a negative value is passed, return all rows except the last abs(n).

### **max(**

    axis: Literal[0] = 0
) → Self

**max(**
    axis: Literal[1]
) → Series

**max(**
    axis: int = 0
) → Self | Series

Агрегируйте столбцы этого фрейма данных до их максимального значения.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.max()
shape: (1, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 3   ┆ 8   ┆ c   │
└─────┴─────┴─────┘
```

### **mean(**
    *, 
    axis: Literal[0] = 0, 
    null_strategy: NullStrategy = 'ignore'
) → Self

**mean(**
    *, 
    axis: Literal[1], 
    null_strategy: NullStrategy = 'ignore'
) → Series

**mean(**
    *, 
    axis: int = 0, 
    null_strategy: NullStrategy = 'ignore'
) → Self | Series

Агрегируйте столбцы этого фрейма данных по их среднему значению.

**Параметры:**

`axis` Либо 0, либо 1.

`null_strategy {‘ignore’, ‘propagate’}` Этот аргумент используется только в том случае, если `axis` == 1.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
        "spam": [True, False, None],
    }
)
df.mean()
shape: (1, 4)
┌─────┬─────┬──────┬──────┐
│ foo ┆ bar ┆ ham  ┆ spam │
│ --- ┆ --- ┆ ---  ┆ ---  │
│ f64 ┆ f64 ┆ str  ┆ f64  │
╞═════╪═════╪══════╪══════╡
│ 2.0 ┆ 7.0 ┆ null ┆ 0.5  │
└─────┴─────┴──────┴──────┘
df.mean(axis=1)
shape: (3,)
Series: 'foo' [f64]
[
    2.666667
    3.0
    5.5
]
```

### **median(**
) → Self

Агрегируйте столбцы этого фрейма данных по их среднему значению.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.median()
shape: (1, 3)
┌─────┬─────┬──────┐
│ foo ┆ bar ┆ ham  │
│ --- ┆ --- ┆ ---  │
│ f64 ┆ f64 ┆ str  │
╞═════╪═════╪══════╡
│ 2.0 ┆ 7.0 ┆ null │
└─────┴─────┴──────┘
```

### **melt(**
    
    id_vars: Sequence[str] | str | None = None, 
    value_vars: Sequence[str] | str | None = None, 
    variable_name: str | None = None, 
    value_name: str | None = None
) → Self

Откорректируйте фрейм данных из широкого формата в длинный.

Необязательно оставляет заданными идентификаторы.

Эта функция полезна для преобразования фрейма данных в формат, в котором один или несколько столбцов являются переменными-идентификаторами (id_vars), в то время как все остальные столбцы, считающиеся измеряемыми переменными (value_vars), “unpivoted” к оси строк, оставляя только два столбца без идентификатора, "variable’ и ‘value’.

**Параметры:**

`id_vars` Столбцы для использования в качестве переменных-идентификаторов.

`value_vars` Значения для использования в качестве переменных-идентификаторов. Если значение value_vars пусто, будут использоваться все столбцы, которых нет в id_vars.

`variable_name` Имя, которое нужно присвоить столбцу переменной. По умолчанию используется значение “переменная”

`value_name` Имя, которое нужно присвоить столбцу значений. По умолчанию используется значение “value”

Пример:
```
df = pl.DataFrame(
    {
        "a": ["x", "y", "z"],
        "b": [1, 3, 5],
        "c": [2, 4, 6],
    }
)
df.melt(id_vars="a", value_vars=["b", "c"])
shape: (6, 3)
┌─────┬──────────┬───────┐
│ a   ┆ variable ┆ value │
│ --- ┆ ---      ┆ ---   │
│ str ┆ str      ┆ i64   │
╞═════╪══════════╪═══════╡
│ x   ┆ b        ┆ 1     │
│ y   ┆ b        ┆ 3     │
│ z   ┆ b        ┆ 5     │
│ x   ┆ c        ┆ 2     │
│ y   ┆ c        ┆ 4     │
│ z   ┆ c        ┆ 6     │
└─────┴──────────┴───────┘
```

### **merge_sorted(**
    
    other: DataFrame, 
    key: str
) → DataFrame

Возьмите два отсортированных фрейма данных и объедините их по отсортированному ключу.

Выходные данные этой операции также будут отсортированы. Вызывающие абоненты несут ответственность за то, чтобы фреймы были отсортированы по этому ключу, в противном случае вывод не будет иметь смысла.

Схемы обоих фреймов данных должны быть одинаковыми.

**Параметры:**

`other` Другой фрейм данных, который необходимо объединить

`key` отсортированный ключ

```
min(axis: Literal[0] = 0) → Self
min(axis: Literal[1]) → Series
min(axis: int = 0) → Self | Series
```
Агрегируйте столбцы этого фрейма данных до их минимального значения.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.min()
shape: (1, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ a   │
└─────┴─────┴─────┘
```
### **n_chunks(**

    strategy: Literal['first'] = 'first'
) → int

**n_chunks(**
    
    strategy: Literal['all']
) → list

Получите количество фрагментов, используемых фрагментированными массивами этого фрейма данных.

**Параметры:**

`strategy {‘first’, ‘all’}` Возвращает количество фрагментов ‘first’ столбца или ‘all’ столбцов в этом фрейме данных.

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 2, 3, 4],
        "b": [0.5, 4, 10, 13],
        "c": [True, True, False, True],
    }
)
df.n_chunks()
1
df.n_chunks(strategy="all")
[1, 1, 1]
```

### **n_unique(**

    subset: str | Expr | Sequence[str | Expr] | None = None
) → int

Возвращает количество уникальных строк или количество уникальных подмножеств строк.

**Параметры:**

`subset` Один или несколько столбцов/выражений, которые определяют, что подсчитывать; опустите, чтобы вернуть количество уникальных строк.

Примечание:

Этот метод работает на уровне фрейма данных; для работы с подмножествами на уровне выражений вы можете вместо этого использовать `struct-packing`, например:

`expr_unique_subset = pl.struct(["a", "b"]).n_unique()`

Если вместо этого вы хотите подсчитать количество уникальных значений для каждого столбца, вы также можете использовать синтаксис на уровне выражений, чтобы вернуть новый фрейм, содержащий этот результат:

```
df = pl.DataFrame([[1, 2, 3], [1, 2, 4]], schema=["a", "b", "c"])
df_nunique = df.select(pl.all().n_unique())
```
В контексте `aggregate `также существует эквивалентный метод для возврата уникальных значений для каждой группы:

`df_agg_nunique = df.groupby(by=["a"]).n_unique()`

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 1, 2, 3, 4, 5],
        "b": [0.5, 0.5, 1.0, 2.0, 3.0, 3.0],
        "c": [True, True, True, False, True, True],
    }
)
df.n_unique()
5
```
Подмножество простых столбцов.
```
df.n_unique(subset=["b", "c"])
4
```
Подмножество выражений.
```
df.n_unique(
    subset=[
        (pl.col("a") // 2),
        (pl.col("c") | (pl.col("b") >= 2)),
    ],
)
3
```
### **null_count(**
) → Self

Создайте новый фрейм данных, который показывает количество нулей в каждом столбце.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, None, 3],
        "bar": [6, 7, None],
        "ham": ["a", "b", "c"],
    }
)
df.null_count()
shape: (1, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ u32 ┆ u32 ┆ u32 │
╞═════╪═════╪═════╡
│ 1   ┆ 1   ┆ 0   │
└─────┴─────┴─────┘
```

### **partition_by(**

    by: str | Iterable[str], 
    *more_by: str, 
    maintain_order: bool = True, 
    as_dict: Literal[False] = False
) → list[Self]

**partition_by(**
    by: str | Iterable[str], 
    *more_by: str, 
    maintain_order: bool = True, 
    as_dict: Literal[True]
) → dict[Any, Self]

Сгруппируйте по заданным столбцам и верните группы в виде отдельных фреймов данных.

**Параметры:**

`by` Название столбца (столбцов), по которому(которым) нужно сгруппировать.

`*more_by` Дополнительные имена столбцов для группировки, указанные в качестве позиционных аргументов.

`maintain_order` Убедитесь, что порядок расположения групп соответствует входным данным. Это медленнее, чем раздел по умолчанию по операции.

`as_dict` Возвращает словарь вместо списка. Ключи словаря - это отдельные групповые значения, которые идентифицируют эту группу.

Пример:

Передайте имя одного столбца для разбиения по этому столбцу.
```
df = pl.DataFrame(
    {
        "a": ["a", "b", "a", "b", "c"],
        "b": [1, 2, 1, 3, 3],
        "c": [5, 4, 3, 2, 1],
    }
)
df.partition_by("a")  
[shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ a   ┆ 1   ┆ 3   │
└─────┴─────┴─────┘, shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 2   ┆ 4   │
│ b   ┆ 3   ┆ 2   │
└─────┴─────┴─────┘, shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘]
```
Разбиение на несколько столбцов осуществляется либо путем передачи списка имен столбцов, либо путем указания имени каждого столбца в качестве позиционного аргумента.
```
df.partition_by("a", "b")  
[shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ a   ┆ 1   ┆ 3   │
└─────┴─────┴─────┘, shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 2   ┆ 4   │
└─────┴─────┴─────┘, shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 3   ┆ 2   │
└─────┴─────┴─────┘, shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘]
```
Верните разделы в виде словаря, указав `as_dict=True`.
```
df.partition_by("a", as_dict=True)  
{'a': shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ a   ┆ 1   ┆ 5   │
│ a   ┆ 1   ┆ 3   │
└─────┴─────┴─────┘, 'b': shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ b   ┆ 2   ┆ 4   │
│ b   ┆ 3   ┆ 2   │
└─────┴─────┴─────┘, 'c': shape: (1, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ c   ┆ 3   ┆ 1   │
└─────┴─────┴─────┘}
```

### **pipe(**

    function: Callable[Concatenate[DataFrame, P], T], 
    *args: P.args, 
    **kwargs: P.kwargs
) → T
Предлагает структурированный способ применения последовательности пользовательских функций (UDFS).

**Параметры:**

`function` Вызываемый; получит фрейм в качестве первого параметра, за которым следуют любые заданные args/kwargs.

`*args` Аргументы для передачи в UDF.

`**kwargs` Аргументы ключевого слова для передачи в UDF.

Заметки:

Рекомендуется использовать отложенный фрейм при конвейерных операциях, чтобы в полной мере воспользоваться преимуществами оптимизации запросов и распараллеливания. Смотрите `df.lazy()`.

Пример:
```
def cast_str_to_int(data, col_name):
    return data.with_columns(pl.col(col_name).cast(pl.Int64))

df = pl.DataFrame({"a": [1, 2, 3, 4], "b": ["10", "20", "30", "40"]})
df.pipe(cast_str_to_int, col_name="b")
shape: (4, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 10  │
│ 2   ┆ 20  │
│ 3   ┆ 30  │
│ 4   ┆ 40  │
└─────┴─────┘
df = pl.DataFrame({"b": [1, 2], "a": [3, 4]})
df
shape: (2, 2)
┌─────┬─────┐
│ b   ┆ a   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 3   │
│ 2   ┆ 4   │
└─────┴─────┘
df.pipe(lambda tdf: tdf.select(sorted(tdf.columns)))
shape: (2, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 3   ┆ 1   │
│ 4   ┆ 2   │
└─────┴─────┘
```

### **pivot(**

    values: Sequence[str] | str, 
    index: Sequence[str] | str, 
    columns: Sequence[str] | str, 
    aggregate_function: PivotAgg | Expr | None | NoDefault = _NoDefault.
    no_default, 
    *, 
    maintain_order: bool = True, 
    sort_columns: bool = False, 
    separator: str = '_'
) → Self

Создайте сводную таблицу в стиле электронной таблицы в качестве фрейма данных.

**Параметры:**

`values` Значения столбцов для агрегирования. Может быть несколько столбцов, если аргументы columns также содержат несколько столбцов.

`index` Один или несколько ключей для группировки по.

`columns` Имя столбца(ов), значения которого будут использоваться в качестве заголовка фрейма выходных данных.

`aggregate_function {‘first’, ‘sum’, ‘max’, ‘min’, ‘mean’, ‘median’, ‘last’, ‘count’}` Предопределенная агрегатная функция str или выражение.

`maintain_order` Отсортируйте сгруппированные ключи таким образом, чтобы порядок вывода был предсказуемым.

`sort_columns` Отсортируйте транспонированные столбцы по названию. По умолчанию используется порядок обнаружения.

`separator` Используется в качестве разделителя в сгенерированных именах столбцов.

Возвращает: DataFrame

Пример:
```
df = pl.DataFrame(
    {
        "foo": ["one", "one", "one", "two", "two", "two"],
        "bar": ["A", "B", "C", "A", "B", "C"],
        "baz": [1, 2, 3, 4, 5, 6],
    }
)
df.pivot(
    values="baz", index="foo", columns="bar", aggregate_function="first"
)
shape: (2, 4)
┌─────┬─────┬─────┬─────┐
│ foo ┆ A   ┆ B   ┆ C   │
│ --- ┆ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 ┆ i64 │
╞═════╪═════╪═════╪═════╡
│ one ┆ 1   ┆ 2   ┆ 3   │
│ two ┆ 4   ┆ 5   ┆ 6   │
└─────┴─────┴─────┴─────┘
```
Запустите выражение как функцию агрегирования
```
df = pl.DataFrame(
    {
        "col1": ["a", "a", "a", "b", "b", "b"],
        "col2": ["x", "x", "x", "x", "y", "y"],
        "col3": [6, 7, 3, 2, 5, 7],
    }
)
df.pivot(
    index="col1",
    columns="col2",
    values="col3",
    aggregate_function=pl.element().tanh().mean(),
)
shape: (2, 3)
┌──────┬──────────┬──────────┐
│ col1 ┆ x        ┆ y        │
│ ---  ┆ ---      ┆ ---      │
│ str  ┆ f64      ┆ f64      │
╞══════╪══════════╪══════════╡
│ a    ┆ 0.998347 ┆ null     │
│ b    ┆ 0.964028 ┆ 0.999954 │
└──────┴──────────┴──────────┘
```
### **product(**
) → DataFrame

Агрегируйте столбцы этого фрейма данных с их значениями продукта.

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 2, 3],
        "b": [0.5, 4, 10],
        "c": [True, True, False],
    }
)
df.product()
shape: (1, 3)
┌─────┬──────┬─────┐
│ a   ┆ b    ┆ c   │
│ --- ┆ ---  ┆ --- │
│ i64 ┆ f64  ┆ i64 │
╞═════╪══════╪═════╡
│ 6   ┆ 20.0 ┆ 0   │
└─────┴──────┴─────┘
```
### **quantile(**

    quantile: float, 
    interpolation: RollingInterpolationMethod = 'nearest'
) → Self

Агрегируйте столбцы этого фрейма данных по их квантильному значению.

**Параметры:**

`quantile` Квантиль между 0,0 и 1,0.

`interpolation {‘nearest’, ‘higher’, ‘lower’, ‘midpoint’, ‘linear’}` Метод интерполяции.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.quantile(0.5, "nearest")
shape: (1, 3)
┌─────┬─────┬──────┐
│ foo ┆ bar ┆ ham  │
│ --- ┆ --- ┆ ---  │
│ f64 ┆ f64 ┆ str  │
╞═════╪═════╪══════╡
│ 2.0 ┆ 7.0 ┆ null │
└─────┴─────┴──────┘
```
### **rechunk(**
) → Self

Повторно распределите данные в этом фрейме данных по непрерывному распределению.

Это обеспечит оптимальную и предсказуемую производительность всех последующих операций.

### **rename(**
    
    mapping: dict[str, str]
) → DataFrame

Переименуйте имена столбцов.

**Параметры:**

`mapping` Пары ключ-значение, которые сопоставляют старое имя с новым.

Пример:
```
df = pl.DataFrame(
    {"foo": [1, 2, 3], "bar": [6, 7, 8], "ham": ["a", "b", "c"]}
)
df.rename({"foo": "apple"})
shape: (3, 3)
┌───────┬─────┬─────┐
│ apple ┆ bar ┆ ham │
│ ---   ┆ --- ┆ --- │
│ i64   ┆ i64 ┆ str │
╞═══════╪═════╪═════╡
│ 1     ┆ 6   ┆ a   │
│ 2     ┆ 7   ┆ b   │
│ 3     ┆ 8   ┆ c   │
└───────┴─────┴─────┘
```
### **replace(**

    column: str, 
    new_column: Series
) → Self

Замените столбец новой серией.

**Параметры:**

`column` Колонка для замены.

`new_column` Новый столбец для вставки.

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
s = pl.Series([10, 20, 30])
df.replace("foo", s)  # works in-place!
shape: (3, 2)
┌─────┬─────┐
│ foo ┆ bar │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 10  ┆ 4   │
│ 20  ┆ 5   │
│ 30  ┆ 6   │
└─────┴─────┘
```
### **replace_at_idx(**

    index: int, 
    series: Series
) → Self

Замените столбец в расположении индекса.

**Параметры:**

`index` Индекс столбца.

`series` Серия, которая заменит столбец.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
s = pl.Series("apple", [10, 20, 30])
df.replace_at_idx(0, s)
shape: (3, 3)
┌───────┬─────┬─────┐
│ apple ┆ bar ┆ ham │
│ ---   ┆ --- ┆ --- │
│ i64   ┆ i64 ┆ str │
╞═══════╪═════╪═════╡
│ 10    ┆ 6   ┆ a   │
│ 20    ┆ 7   ┆ b   │
│ 30    ┆ 8   ┆ c   │
└───────┴─────┴─────┘
```
### **reverse(**
) → DataFrame

Переверните фрейм данных.

Пример:
```
df = pl.DataFrame(
    {
        "key": ["a", "b", "c"],
        "val": [1, 2, 3],
    }
)
df.reverse()
shape: (3, 2)
┌─────┬─────┐
│ key ┆ val │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ c   ┆ 3   │
│ b   ┆ 2   │
│ a   ┆ 1   │
└─────┴─────┘
```
### **row(**

    index: int | None = None, 
    *, 
    by_predicate: Expr | None = None, 
    named: Literal[False] = False
) → tuple[Any, ...]

**row(**
    
    index: int | None = None, 
    *, 
    by_predicate: Expr | None = None, 
    named: Literal[True]
) → dict[str, Any]

Получите значения одной строки либо по индексу, либо по предикату.

**Параметры:**

`index`
Индекс строки.

`by_predicate`
Выберите строку в соответствии с заданным выражением/предикатом.

`named`
Возвращает словарь вместо кортежа. Словарь - это сопоставление имени столбца со значением строки. Это дороже, чем возврат обычного кортежа, но позволяет получить доступ к значениям по имени столбца.

Возвращает: Кортеж (по умолчанию) или словарь значений строк.

Предупреждение

Вы никогда не должны использовать этот метод для перебора фрейма данных; если вам требуется итерация строк, вам следует настоятельно предпочесть использование `iter_rows()` вместо этого.

Пртмечание:

Параметры `index` и `by_predicate` являются взаимоисключающими. Кроме того, для обеспечения ясности параметр `by_predicate` должен быть задан с помощью ключевого слова.

При использовании `by_predicate` это условие ошибки, если возвращается что-либо, отличное от одной строки; более одной строки вызывает `TooManyRowsReturnedError`, а нулевые строки не вызовут `NoRowsReturnedError` (оба наследуются от `RowsError`).

Пример:

Укажите индекс, который вернет строку с заданным индексом в виде кортежа.
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.row(2)
(3, 8, 'c')
```
Укажите `named=True`, чтобы вместо этого получить словарь с отображением имен столбцов в значения строк.
```
df.row(2, named=True)
{'foo': 3, 'bar': 8, 'ham': 'c'}
```
Используйте `by_predicate`, чтобы вернуть строку, соответствующую заданному предикату.
```
df.row(by_predicate=(pl.col("ham") == "b"))
(2, 7, 'b')
```
### **rows(**

    *, 
    named: Literal[False] = False
) → list[tuple[Any, ...]]

**rows(**

    *, 
    named: Literal[True]
) → list[dict[str, Any]]

Возвращает все данные в DataFrame в виде списка строк собственных значений python.

**Параметры:**

`named` Возвращайте словари вместо кортежей. Словари представляют собой сопоставление имени столбца со значением строки. Это дороже, чем возврат обычного кортежа, но позволяет получить доступ к значениям по имени столбца.

Возвращает: Список кортежей (по умолчанию) или словарей значений строк.

Предупреждение

Итерация по строкам не является оптимальной, поскольку базовые данные хранятся в виде столбцов; там, где это возможно, отдавайте предпочтение экспорту с помощью одного из специальных методов экспорта/вывода.

Примечание:

Если у вас есть временные значения с точностью до ns, вы должны знать, что python изначально поддерживает только точность до us; если это имеет значение, вам следует экспортировать в другой формат.

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 3, 5],
        "b": [2, 4, 6],
    }
)
df.rows()
[(1, 2), (3, 4), (5, 6)]
df.rows(named=True)
[{'a': 1, 'b': 2}, {'a': 3, 'b': 4}, {'a': 5, 'b': 6}]
```
### **sample(**

    n: int | None = None, 
    *, 
    fraction: float | None = None, 
    with_replacement: bool = False, 
    shuffle: bool = False, 
    seed: int | None = None
) → Self

Выборка из этого фрейма данных.

**Параметры:**

`n` Количество элементов, подлежащих возврату. Не может использоваться с дробью. Значение по умолчанию равно 1, если дробь равна None.

`fraction` Часть элементов, подлежащих возврату. Не может использоваться с n.

`with_replacement` Разрешите выборку значений более одного раза.

`shuffle` Если установлено значение True, порядок выбранных строк будет перетасован. Если установлено значение False (по умолчанию), порядок возвращаемых строк не будет ни стабильным, ни полностью случайным.

`seed` Начальное значение для генератора случайных чисел. Если установлено значение None (по умолчанию), с помощью модуля random генерируется случайное начальное значение.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.sample(n=2, seed=0)  
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 3   ┆ 8   ┆ c   │
│ 2   ┆ 7   ┆ b   │
└─────┴─────┴─────┘
property schema: SchemaDict[source]
```
Получите dict[column name, DataType].

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
df.schema
{'foo': Int64, 'bar': Float64, 'ham': Utf8}
```
### **select(**
    
    *exprs: IntoExpr | Iterable[IntoExpr], 
    **named_exprs: IntoExpr
) → DataFrame

Выберите столбцы из этого фрейма данных.

**Параметры:**

`*exprs` Столбцы для выбора, указанные в качестве позиционных аргументов. Принимает ввод выражения. Строки анализируются как имена столбцов, другие входные данные, не являющиеся выражениями, анализируются как литералы.

`**named_exprs` Дополнительные столбцы для выбора, указанные в качестве аргументов ключевого слова. Столбцы будут переименованы в соответствии с используемым ключевым словом.

Пример:

Передайте имя столбца, чтобы выбрать этот столбец.
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.select("foo")
shape: (3, 1)
┌─────┐
│ foo │
│ --- │
│ i64 │
╞═════╡
│ 1   │
│ 2   │
│ 3   │
└─────┘
```
Можно выбрать несколько столбцов, передав список имен столбцов.
```
df.select(["foo", "bar"])
shape: (3, 2)
┌─────┬─────┐
│ foo ┆ bar │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 6   │
│ 2   ┆ 7   │
│ 3   ┆ 8   │
└─────┴─────┘
```
Несколько столбцов также можно выбрать, используя позиционные аргументы вместо списка. Также принимаются выражения.
```
df.select(pl.col("foo"), pl.col("bar") + 1)
shape: (3, 2)
┌─────┬─────┐
│ foo ┆ bar │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 7   │
│ 2   ┆ 8   │
│ 3   ┆ 9   │
└─────┴─────┘
```
Используйте аргументы ключевых слов, чтобы легко присвоить имена входным данным вашего выражения.
```
df.select(threshold=pl.when(pl.col("foo") > 2).then(10).otherwise(0))
shape: (3, 1)
┌───────────┐
│ threshold │
│ ---       │
│ i32       │
╞═══════════╡
│ 0         │
│ 0         │
│ 10        │
└───────────┘
```
Выражения с несколькими выходными данными можно автоматически создавать как структуры, включив экспериментальную настройку Config.set_auto_structify(True):
```
with pl.Config(auto_structify=True):
    df.select(
        is_odd=(pl.col(pl.INTEGER_DTYPES) % 2).suffix("_is_odd"),
    )

shape: (3, 1)
┌───────────┐
│ is_odd    │
│ ---       │
│ struct[2] │
╞═══════════╡
│ {1,0}     │
│ {0,1}     │
│ {1,0}     │
└───────────┘
```
### **set_sorted(**

    column: str | Iterable[str], 
    *more_columns: str, 
    descending: bool = False
) → DataFrame

Укажите, что один или несколько столбцов отсортированы.

**Параметры:**

`column` Столбцы, которые сортируются

`more_columns` Дополнительные столбцы, которые сортируются, указываются в качестве позиционных аргументов.

`descending` Сортируются ли столбцы в порядке убывания.

свойство `shape: tuple[int, int]` Получите форму фрейма данных.

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3, 4, 5]})
df.shape
(5, 1)
```
### **shift(**

    periods: int
) → Self

Сдвиг значений на заданный период.

**Параметры:**

`periods` Количество мест для сдвига (может быть отрицательным).

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.shift(periods=1)
shape: (3, 3)
┌──────┬──────┬──────┐
│ foo  ┆ bar  ┆ ham  │
│ ---  ┆ ---  ┆ ---  │
│ i64  ┆ i64  ┆ str  │
╞══════╪══════╪══════╡
│ null ┆ null ┆ null │
│ 1    ┆ 6    ┆ a    │
│ 2    ┆ 7    ┆ b    │
└──────┴──────┴──────┘
df.shift(periods=-1)
shape: (3, 3)
┌──────┬──────┬──────┐
│ foo  ┆ bar  ┆ ham  │
│ ---  ┆ ---  ┆ ---  │
│ i64  ┆ i64  ┆ str  │
╞══════╪══════╪══════╡
│ 2    ┆ 7    ┆ b    │
│ 3    ┆ 8    ┆ c    │
│ null ┆ null ┆ null │
└──────┴──────┴──────┘
```
### **shift_and_fill(**

    fill_value: int | str | float, 
    *, 
    periods: int = 1
) → DataFrame

Сдвиньте значения на заданный период и заполните полученные значения null.

**Параметры:**

`fill_value` заполните этим значением None values.

`periods` Количество мест для сдвига (может быть отрицательным).

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.shift_and_fill(periods=1, fill_value=0)
shape: (3, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 0   ┆ 0   ┆ 0   │
│ 1   ┆ 6   ┆ a   │
│ 2   ┆ 7   ┆ b   │
└─────┴─────┴─────┘
```
### **shrink_to_fit(**

    *, 
    in_place: bool = False
) → Self

Сократите использование памяти фрейма данных.

Сжимается в соответствии с точным объемом, необходимым для хранения данных.

### **slice(**

    offset: int, 
    length: int | None = None
) → Self

Получите фрагмент этого фрейма данных.

**Параметры:**

`offset` Начальный индекс. Поддерживается отрицательная индексация.

`length` Длина фрагмента. Если установлено значение None, будут выбраны все строки, начинающиеся со смещения.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.0, 7.0, 8.0],
        "ham": ["a", "b", "c"],
    }
)
df.slice(1, 2)
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ f64 ┆ str │
╞═════╪═════╪═════╡
│ 2   ┆ 7.0 ┆ b   │
│ 3   ┆ 8.0 ┆ c   │
└─────┴─────┴─────┘
```
### **sort(**

    by: IntoExpr | Iterable[IntoExpr], 
    *more_by: IntoExpr, 
    descending: bool | Sequence[bool] = False, 
    nulls_last: bool = False
) → DataFrame

Отсортируйте фрейм данных по заданным столбцам.

**Параметры:**

`by` Столбцы для сортировки. Принимает ввод выражения. Строки анализируются как имена столбцов.

`*more_by` Дополнительные столбцы для сортировки, указанные в качестве позиционных аргументов.

`descending` Сортировка в порядке убывания. При сортировке по нескольким столбцам можно указать для каждого столбца, передав последовательность логических значений.

`nulls_last` Размещайте нулевые значения последними.

Пример:

Передайте имя одного столбца для сортировки по этому столбцу.
```
df = pl.DataFrame(
    {
        "a": [1, 2, None],
        "b": [6.0, 5.0, 4.0],
        "c": ["a", "c", "b"],
    }
)
df.sort("a")
shape: (3, 3)
┌──────┬─────┬─────┐
│ a    ┆ b   ┆ c   │
│ ---  ┆ --- ┆ --- │
│ i64  ┆ f64 ┆ str │
╞══════╪═════╪═════╡
│ null ┆ 4.0 ┆ b   │
│ 1    ┆ 6.0 ┆ a   │
│ 2    ┆ 5.0 ┆ c   │
└──────┴─────┴─────┘
```
Также поддерживается сортировка по выражениям.
```
df.sort(pl.col("a") + pl.col("b") * 2, nulls_last=True)
shape: (3, 3)
┌──────┬─────┬─────┐
│ a    ┆ b   ┆ c   │
│ ---  ┆ --- ┆ --- │
│ i64  ┆ f64 ┆ str │
╞══════╪═════╪═════╡
│ 2    ┆ 5.0 ┆ c   │
│ 1    ┆ 6.0 ┆ a   │
│ null ┆ 4.0 ┆ b   │
└──────┴─────┴─────┘
```
Сортировка по нескольким столбцам осуществляется путем передачи списка столбцов.
```
df.sort(["c", "a"], descending=True)
shape: (3, 3)
┌──────┬─────┬─────┐
│ a    ┆ b   ┆ c   │
│ ---  ┆ --- ┆ --- │
│ i64  ┆ f64 ┆ str │
╞══════╪═════╪═════╡
│ 2    ┆ 5.0 ┆ c   │
│ null ┆ 4.0 ┆ b   │
│ 1    ┆ 6.0 ┆ a   │
└──────┴─────┴─────┘
```
Или используйте позиционные аргументы для сортировки по нескольким столбцам таким же образом.
```
df.sort("c", "a", descending=[False, True])
shape: (3, 3)
┌──────┬─────┬─────┐
│ a    ┆ b   ┆ c   │
│ ---  ┆ --- ┆ --- │
│ i64  ┆ f64 ┆ str │
╞══════╪═════╪═════╡
│ 1    ┆ 6.0 ┆ a   │
│ null ┆ 4.0 ┆ b   │
│ 2    ┆ 5.0 ┆ c   │
└──────┴─────┴─────┘
```
### **std(**
    
    ddof: int = 1
) → Self

Агрегируйте столбцы этого фрейма данных по их значению стандартного отклонения.

**Параметры:**

`ddof` “Дельта-степени свободы”: делитель, используемый при вычислении, равен N - ddof, где N представляет количество элементов. По умолчанию значение ddof равно 1.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.std()
shape: (1, 3)
┌─────┬─────┬──────┐
│ foo ┆ bar ┆ ham  │
│ --- ┆ --- ┆ ---  │
│ f64 ┆ f64 ┆ str  │
╞═════╪═════╪══════╡
│ 1.0 ┆ 1.0 ┆ null │
└─────┴─────┴──────┘
df.std(ddof=0)
shape: (1, 3)
┌──────────┬──────────┬──────┐
│ foo      ┆ bar      ┆ ham  │
│ ---      ┆ ---      ┆ ---  │
│ f64      ┆ f64      ┆ str  │
╞══════════╪══════════╪══════╡
│ 0.816497 ┆ 0.816497 ┆ null │
└──────────┴──────────┴──────┘
```
### **sum(**
    
    *, 
    axis: Literal[0] = 0, 
    null_strategy: NullStrategy = 'ignore'
) → Self

**sum(**

    *, 
    axis: Literal[1], 
    null_strategy: NullStrategy = 'ignore'
) → Series

**sum(**

    *, 
    axis: int = 0, 
    null_strategy: NullStrategy = 'ignore'
) → Self | Series

Суммируйте столбцы этого фрейма данных до их суммарного значения.

**Параметры:**

`axis` Либо 0, либо 1.

`null_strategy {‘ignore’, ‘propagate’}` Этот аргумент используется только в том случае, если axis == 1.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.sum()
shape: (1, 3)
┌─────┬─────┬──────┐
│ foo ┆ bar ┆ ham  │
│ --- ┆ --- ┆ ---  │
│ i64 ┆ i64 ┆ str  │
╞═════╪═════╪══════╡
│ 6   ┆ 21  ┆ null │
└─────┴─────┴──────┘
df.sum(axis=1)
shape: (3,)
Series: 'foo' [str]
[
        "16a"
        "27b"
        "38c"
]
```
### **tail(**

    n: int = 5
) → Self

Получаем последние n строк.

**Параметры:**

`n` Количество возвращаемых строк. Если передано отрицательное значение, верните все строки, кроме первой abs(n).

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3, 4, 5],
        "bar": [6, 7, 8, 9, 10],
        "ham": ["a", "b", "c", "d", "e"],
    }
)
df.tail(3)
shape: (3, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 3   ┆ 8   ┆ c   │
│ 4   ┆ 9   ┆ d   │
│ 5   ┆ 10  ┆ e   │
└─────┴─────┴─────┘
```
Передайте отрицательное значение, чтобы получить все строки, кроме первой abs(n).
```
df.tail(-3)
shape: (2, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 4   ┆ 9   ┆ d   │
│ 5   ┆ 10  ┆ e   │
└─────┴─────┴─────┘
```
### **take_every(**

    n: int
) → DataFrame

Возьмите каждую n-ю строку в DataFrame и верните как новый DataFrame.

Пример:
```
s = pl.DataFrame({"a": [1, 2, 3, 4], "b": [5, 6, 7, 8]})
s.take_every(2)
shape: (2, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 5   │
│ 3   ┆ 7   │
└─────┴─────┘
```
### **to_arrow(**
) → Table[s

Соберите лежащие в основе массивы массивов в таблицу массивов.

Эта операция в основном представляет собой нулевое копирование.

Типы данных, которые выполняют копирование:
CategoricalType

Пример:
```
df = pl.DataFrame(
    {"foo": [1, 2, 3, 4, 5, 6], "bar": ["a", "b", "c", "d", "e", "f"]}
)
df.to_arrow()
pyarrow.Table
foo: int64
bar: large_string
----
foo: [[1,2,3,4,5,6]]
bar: [["a","b","c","d","e","f"]]
```
### **to_dict(**

    as_series: Literal[True] = True
) → dict[str, Series]

**to_dict(**

    as_series: Literal[False]
) → dict[str, list[Any]]

**to_dict(**

    as_series: bool = True
) → dict[str, Series] | dict[str, list[Any]]

Преобразуйте фрейм данных в словарь, сопоставляющий имя столбца значениям.

**Параметры:**

`as_series`
True -> Values are series False -> Values are List[Any]

Пример:
```
df = pl.DataFrame(
    {
        "A": [1, 2, 3, 4, 5],
        "fruits": ["banana", "banana", "apple", "apple", "banana"],
        "B": [5, 4, 3, 2, 1],
        "cars": ["beetle", "audi", "beetle", "beetle", "beetle"],
        "optional": [28, 300, None, 2, -30],
    }
)
df
shape: (5, 5)
┌─────┬────────┬─────┬────────┬──────────┐
│ A   ┆ fruits ┆ B   ┆ cars   ┆ optional │
│ --- ┆ ---    ┆ --- ┆ ---    ┆ ---      │
│ i64 ┆ str    ┆ i64 ┆ str    ┆ i64      │
╞═════╪════════╪═════╪════════╪══════════╡
│ 1   ┆ banana ┆ 5   ┆ beetle ┆ 28       │
│ 2   ┆ banana ┆ 4   ┆ audi   ┆ 300      │
│ 3   ┆ apple  ┆ 3   ┆ beetle ┆ null     │
│ 4   ┆ apple  ┆ 2   ┆ beetle ┆ 2        │
│ 5   ┆ banana ┆ 1   ┆ beetle ┆ -30      │
└─────┴────────┴─────┴────────┴──────────┘
df.to_dict(as_series=False)
{'A': [1, 2, 3, 4, 5],
'fruits': ['banana', 'banana', 'apple', 'apple', 'banana'],
'B': [5, 4, 3, 2, 1],
'cars': ['beetle', 'audi', 'beetle', 'beetle', 'beetle'],
'optional': [28, 300, None, 2, -30]}
df.to_dict(as_series=True)
{'A': shape: (5,)
Series: 'A' [i64]
[
    1
    2
    3
    4
    5
], 'fruits': shape: (5,)
Series: 'fruits' [str]
[
    "banana"
    "banana"
    "apple"
    "apple"
    "banana"
], 'B': shape: (5,)
Series: 'B' [i64]
[
    5
    4
    3
    2
    1
], 'cars': shape: (5,)
Series: 'cars' [str]
[
    "beetle"
    "audi"
    "beetle"
    "beetle"
    "beetle"
], 'optional': shape: (5,)
Series: 'optional' [i64]
[
    28
    300
    null
    2
    -30
]}
```
### **to_dicts(**
) → list[dict[str, Any]]

Преобразуйте каждую строку в словарь собственных значений python.

Примечание:

Если у вас есть временные значения с точностью до ns, вы должны знать, что python изначально поддерживает только точность до us; если это имеет значение, вам следует экспортировать в другой формат.

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
df.to_dicts()
[{'foo': 1, 'bar': 4}, {'foo': 2, 'bar': 5}, {'foo': 3, 'bar': 6}]
```
### **to_dummies(**

    columns: str | Sequence[str] | None = None, 
    *, 
    separator: str = '_'
) → Self

Преобразуйте категориальные переменные в фиктивные/индикаторные переменные.

**Параметры:**

`columns` Имя столбца (столбцов), которые должны быть преобразованы в фиктивные переменные. Если задано значение None (по умолчанию), преобразуйте все столбцы.

`separator` Разделитель, используемый при генерации имен столбцов.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2],
        "bar": [3, 4],
        "ham": ["a", "b"],
    }
)
df.to_dummies()
shape: (2, 6)
┌───────┬───────┬───────┬───────┬───────┬───────┐
│ foo_1 ┆ foo_2 ┆ bar_3 ┆ bar_4 ┆ ham_a ┆ ham_b │
│ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │
│ u8    ┆ u8    ┆ u8    ┆ u8    ┆ u8    ┆ u8    │
╞═══════╪═══════╪═══════╪═══════╪═══════╪═══════╡
│ 1     ┆ 0     ┆ 1     ┆ 0     ┆ 1     ┆ 0     │
│ 0     ┆ 1     ┆ 0     ┆ 1     ┆ 0     ┆ 1     │
└───────┴───────┴───────┴───────┴───────┴───────┘
```
### **to_init_repr(**

    n: int = 1000
) → str

Преобразуйте фрейм данных в создаваемое строковое представление.

**Параметры:**

`n` Используйте только первые n строк.

Пример:
```
df = pl.DataFrame(
    [
        pl.Series("foo", [1, 2, 3], dtype=pl.UInt8),
        pl.Series("bar", [6.0, 7.0, 8.0], dtype=pl.Float32),
        pl.Series("ham", ["a", "b", "c"], dtype=pl.Categorical),
    ]
)
print(df.to_init_repr())
pl.DataFrame(
    [
        pl.Series("foo", [1, 2, 3], dtype=pl.UInt8),
        pl.Series("bar", [6.0, 7.0, 8.0], dtype=pl.Float32),
        pl.Series("ham", ['a', 'b', 'c'], dtype=pl.Categorical),
    ]
)
df_from_str_repr = eval(df.to_init_repr())
df_from_str_repr
shape: (3, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ u8  ┆ f32 ┆ cat │
╞═════╪═════╪═════╡
│ 1   ┆ 6.0 ┆ a   │
│ 2   ┆ 7.0 ┆ b   │
│ 3   ┆ 8.0 ┆ c   │
└─────┴─────┴─────┘
```
### **to_numpy(**

    structured: bool = False
) → ndarray[Any, Any]

Преобразуйте фрейм данных в двумерный массив NumPy.

Эта операция клонирует данные.

**Параметры:**

`structured` Необязательно возвращать структурированный массив с именами полей и типами, соответствующими схеме фрейма данных.

Примечание:

Если вы пытаетесь преобразовать Utf8 в массив, вам нужно будет установить pyarrow.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6.5, 7.0, 8.5],
        "ham": ["a", "b", "c"],
    },
    schema_overrides={"foo": pl.UInt8, "bar": pl.Float32},
)
```
Экспорт в стандартный 2D-массив numpy.
```
df.to_numpy()
array([[1, 6.5, 'a'],
       [2, 7.0, 'b'],
       [3, 8.5, 'c']], dtype=object)
```
Экспорт в структурированный массив, который позволяет лучше сохранять данные отдельных столбцов, такие как `name` и `dtype`…
```
df.to_numpy(structured=True)
array([(1, 6.5, 'a'), (2, 7. , 'b'), (3, 8.5, 'c')],
      dtype=[('foo', 'u1'), ('bar', '<f4'), ('ham', '<U1')])
```
…необязательно копирование с нуля в виде представления массива записей:
```
import numpy as np
df.to_numpy(True).view(np.recarray)
rec.array([(1, 6.5, 'a'), (2, 7. , 'b'), (3, 8.5, 'c')],
          dtype=[('foo', 'u1'), ('bar', '<f4'), ('ham', '<U1')])
```
### **to_pandas(**

    *args: Any, 
    use_pyarrow_extension_array: bool = False, 
    **kwargs: Any
) → DataFrame

Приведение к фрейму данных pandas.

Для этого необходимо, чтобы были установлены pandas и yarrow. Эта операция клонирует данные, если только `use_pyarrow_extension_array=True`.

**Параметры:**

`use_pyarrow_extension_array` Используйте массивы с расширением с поддержкой PyArrow вместо массивов numpy для каждого столбца фрейма данных pandas; это позволяет выполнять операции нулевого копирования и сохранять нулевые значения. Последующие операции с результирующим фреймом данных pandas могут инициировать преобразование в массивы NumPy, если эта операция не поддерживается вычислительными функциями pyarrow.

`kwargs` Аргументы будут отправлены в `yarrow.Таблица.to_pandas()`.

Возвращает: pandas.DataFrame

Пример:
```
import pandas
df1 = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
pandas_df1 = df1.to_pandas()
type(pandas_df1)
<class 'pandas.core.frame.DataFrame'>
pandas_df1.dtypes
foo     int64
bar     int64
ham    object
dtype: object
df2 = pl.DataFrame(
    {
        "foo": [1, 2, None],
        "bar": [6, None, 8],
        "ham": [None, "b", "c"],
    }
)
pandas_df2 = df2.to_pandas()
pandas_df2
   foo  bar   ham
0  1.0  6.0  None
1  2.0  NaN     b
2  NaN  8.0     c
pandas_df2.dtypes
foo    float64
bar    float64
ham     object
dtype: object
pandas_df2_pa = df2.to_pandas(
    use_pyarrow_extension_array=True
)  
pandas_df2_pa  
    foo   bar   ham
0     1     6  <NA>
1     2  <NA>     b
2  <NA>     8     c
pandas_df2_pa.dtypes  
foo           int64[pyarrow]
bar           int64[pyarrow]
ham    large_string[pyarrow]
dtype: object
```
### **to_series(**

    index: int = 0
) → Series

Выберите столбец как Series в расположении индекса.

**Параметры:**

`index` Место отбора.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.to_series(1)
shape: (3,)
Series: 'bar' [i64]
[
        6
        7
        8
]
```
### **to_struct(**

    name: str
) → Series

Преобразуйте фрейм данных в последовательность типов Struct.

**Параметры:**

`name` Название серии структур

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 2, 3, 4, 5],
        "b": ["one", "two", "three", "four", "five"],
    }
)
df.to_struct("nums")
shape: (5,)
Series: 'nums' [struct[2]]
[
    {1,"one"}
    {2,"two"}
    {3,"three"}
    {4,"four"}
    {5,"five"}
]
```
### **top_k(**

    k: int, 
    *, 
    by: IntoExpr | Iterable[IntoExpr], 
    descending: bool | Sequence[bool] = False, 
    nulls_last: bool = False
) → DataFrame

Возвращает k самых больших элементов.

Если `descending=True`, то будут заданы наименьшие элементы.

**Параметры:**

`k` Количество возвращаемых строк.

`by` Столбцы, включенные в порядке сортировки. Принимает ввод выражения. Строки анализируются как имена столбцов.

`descending` Верните наименьшее значение ‘k’. Top-k по нескольким столбцам может быть задан для каждого столбца путем передачи последовательности логических значений.

`nulls_last` Размещайте нулевые значения последними.

Пример:
```
df = pl.DataFrame(
    {
        "a": ["a", "b", "a", "b", "b", "c"],
        "b": [2, 1, 1, 3, 2, 1],
    }
)
```
Получите строки, содержащие 4 наибольших значения в столбце b.
```
df.top_k(4, by="b")
shape: (4, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ b   ┆ 3   │
│ a   ┆ 2   │
│ b   ┆ 2   │
│ b   ┆ 1   │
└─────┴─────┘
```
Получите строки, содержащие 4 наибольших значения, при сортировке по столбцам b и a.
```
df.top_k(4, by=["b", "a"])
shape: (4, 2)
┌─────┬─────┐
│ a   ┆ b   │
│ --- ┆ --- │
│ str ┆ i64 │
╞═════╪═════╡
│ b   ┆ 3   │
│ b   ┆ 2   │
│ a   ┆ 2   │
│ c   ┆ 1   │
└─────┴─────┘
```
### **transpose(**
    
    *, 
    include_header: bool = False, 
    header_name: str = 'column', 
    column_names: Iterable[str] | None = None
) → Self

Транспонировать фрейм данных по диагонали.

**Параметры:**

`include_header` Если задано, имена столбцов будут добавлены в качестве первого столбца.

`header_name` Если задан параметр include_header, это определяет имя столбца, который будет вставлен.

`column_names` Необязательный итерационный параметр, который выдает имена столбцов. Будет использоваться для замены столбцов во фрейме данных.

Возвращает: DataFrame

Примечание:

Это очень дорогостоящая операция. Возможно, вы можете сделать это по-другому.

Пример:
```
df = pl.DataFrame({"a": [1, 2, 3], "b": [1, 2, 3]})
df.transpose(include_header=True)
shape: (2, 4)
┌────────┬──────────┬──────────┬──────────┐
│ column ┆ column_0 ┆ column_1 ┆ column_2 │
│ ---    ┆ ---      ┆ ---      ┆ ---      │
│ str    ┆ i64      ┆ i64      ┆ i64      │
╞════════╪══════════╪══════════╪══════════╡
│ a      ┆ 1        ┆ 2        ┆ 3        │
│ b      ┆ 1        ┆ 2        ┆ 3        │
└────────┴──────────┴──────────┴──────────┘
```
Замените автоматически сгенерированные имена столбцов списком
```
df.transpose(include_header=False, column_names=["a", "b", "c"])
shape: (2, 3)
┌─────┬─────┬─────┐
│ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ i64 │
╞═════╪═════╪═════╡
│ 1   ┆ 2   ┆ 3   │
│ 1   ┆ 2   ┆ 3   │
└─────┴─────┴─────┘
```
Включите заголовок в виде отдельного столбца
```
df.transpose(
    include_header=True, header_name="foo", column_names=["a", "b", "c"]
)
shape: (2, 4)
┌─────┬─────┬─────┬─────┐
│ foo ┆ a   ┆ b   ┆ c   │
│ --- ┆ --- ┆ --- ┆ --- │
│ str ┆ i64 ┆ i64 ┆ i64 │
╞═════╪═════╪═════╪═════╡
│ a   ┆ 1   ┆ 2   ┆ 3   │
│ b   ┆ 1   ┆ 2   ┆ 3   │
└─────┴─────┴─────┴─────┘
```
Замените автоматически сгенерированный столбец именами столбцов из функции генератора
```
def name_generator():
    base_name = "my_column_"
    count = 0
    while True:
        yield f"{base_name}{count}"
        count += 1

df.transpose(include_header=False, column_names=name_generator())
shape: (2, 3)
┌─────────────┬─────────────┬─────────────┐
│ my_column_0 ┆ my_column_1 ┆ my_column_2 │
│ ---         ┆ ---         ┆ ---         │
│ i64         ┆ i64         ┆ i64         │
╞═════════════╪═════════════╪═════════════╡image.png
│ 1           ┆ 2           ┆ 3           │
│ 1           ┆ 2           ┆ 3           │
└─────────────┴─────────────┴─────────────┘
```
### **unique(**

    subset: str | Sequence[str] | None = None, 
    *, 
    keep: UniqueKeepStrategy = 'any', 
    maintain_order: bool = False
) → DataFrame

Удалите повторяющиеся строки из этого фрейма данных.

**Параметры:**

`subset` Column name(s) to consider when identifying duplicates. If set to None (default), use all columns.

`keep {‘first’, ‘last’, ‘any’, ‘none’}` Какую из повторяющихся строк сохранить.

"любой": не дает никакой гарантии того, какая строка сохранена.
Это позволяет проводить большую оптимизацию.

`none`: не сохраняйте повторяющиеся строки.

`first`: сохранить первую уникальную строку.

`last`: сохранить последнюю уникальную строку.

`maintain_order` Сохраняйте тот же порядок, что и в исходном фрейме данных. Это более дорогостоящее вычисление. Установка значения `True` блокирует возможность запуска на движке потоковой передачи.

Возвращает: Фрейм данных с уникальными строками.

Предупреждение

Этот метод завершится неудачей, если во фрейме данных или подмножестве есть столбец типа List.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3, 1],
        "bar": ["a", "a", "a", "a"],
        "ham": ["b", "b", "b", "b"],
    }
)
df.unique(maintain_order=True)
shape: (3, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ str ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ a   ┆ b   │
│ 2   ┆ a   ┆ b   │
│ 3   ┆ a   ┆ b   │
└─────┴─────┴─────┘
df.unique(subset=["bar", "ham"], maintain_order=True)
shape: (1, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ str ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ a   ┆ b   │
└─────┴─────┴─────┘
df.unique(keep="last", maintain_order=True)
shape: (3, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ str ┆ str │
╞═════╪═════╪═════╡
│ 2   ┆ a   ┆ b   │
│ 3   ┆ a   ┆ b   │
│ 1   ┆ a   ┆ b   │
└─────┴─────┴─────┘
```
### **unnest(**
    
    columns: str | Sequence[str], 
    *more_columns: str
) → Self

Разложите столбцы структуры на отдельные столбцы для каждого из их полей.

Новые столбцы будут вставлены во фрейм данных в месте расположения столбца struct.

**Параметры:**

`columns` Имя столбца(ов) структуры, который(которые) не должен быть указан.

`*more_columns` Дополнительные столбцы для удаления, указанные в качестве позиционных аргументов.

Пример:
```
df = pl.DataFrame(
    {
        "before": ["foo", "bar"],
        "t_a": [1, 2],
        "t_b": ["a", "b"],
        "t_c": [True, None],
        "t_d": [[1, 2], [3]],
        "after": ["baz", "womp"],
    }
).select("before", pl.struct(pl.col("^t_.$")).alias("t_struct"), "after")
df
shape: (2, 3)
┌────────┬─────────────────────┬───────┐
│ before ┆ t_struct            ┆ after │
│ ---    ┆ ---                 ┆ ---   │
│ str    ┆ struct[4]           ┆ str   │
╞════════╪═════════════════════╪═══════╡
│ foo    ┆ {1,"a",true,[1, 2]} ┆ baz   │
│ bar    ┆ {2,"b",null,[3]}    ┆ womp  │
└────────┴─────────────────────┴───────┘
df.unnest("t_struct")
shape: (2, 6)
┌────────┬─────┬─────┬──────┬───────────┬───────┐
│ before ┆ t_a ┆ t_b ┆ t_c  ┆ t_d       ┆ after │
│ ---    ┆ --- ┆ --- ┆ ---  ┆ ---       ┆ ---   │
│ str    ┆ i64 ┆ str ┆ bool ┆ list[i64] ┆ str   │
╞════════╪═════╪═════╪══════╪═══════════╪═══════╡
│ foo    ┆ 1   ┆ a   ┆ true ┆ [1, 2]    ┆ baz   │
│ bar    ┆ 2   ┆ b   ┆ null ┆ [3]       ┆ womp  │
└────────┴─────┴─────┴──────┴───────────┴───────┘
```
### **unstack(**

    step: int, 
    how: UnstackDirection = 'vertical', 
    columns: str | Sequence[str] | None = None, 
    fill_values: list[Any] | None = None
) → DataFrame

Преобразуйте длинную таблицу в широкую форму, не выполняя агрегирование.

Это может быть намного быстрее, чем сводная таблица, потому что она может пропустить фазу группировки.

**Параметры:**

`step` Количество строк в неупакованном фрейме.

`how { ‘vertical’, ‘horizontal’ }` Направление открепления.

`columns` Имя столбца (столбцов), который(которые) необходимо включить в операцию. Если задано значение None (по умолчанию), используйте все столбцы.

`fill_values` Заполните этим значением значения, которые не соответствуют новому размеру.

Предупреждение

Эта функциональность является экспериментальной и может быть подвержена изменениям, но это не считается кардинальным изменением.

Пример:
```
from string import ascii_uppercase
df = pl.DataFrame(
    {
        "col1": list(ascii_uppercase[0:9]),
        "col2": pl.arange(0, 9, eager=True),
    }
)
df
shape: (9, 2)
┌──────┬──────┐
│ col1 ┆ col2 │
│ ---  ┆ ---  │
│ str  ┆ i64  │
╞══════╪══════╡
│ A    ┆ 0    │
│ B    ┆ 1    │
│ C    ┆ 2    │
│ D    ┆ 3    │
│ E    ┆ 4    │
│ F    ┆ 5    │
│ G    ┆ 6    │
│ H    ┆ 7    │
│ I    ┆ 8    │
└──────┴──────┘
df.unstack(step=3, how="vertical")
shape: (3, 6)
┌────────┬────────┬────────┬────────┬────────┬────────┐
│ col1_0 ┆ col1_1 ┆ col1_2 ┆ col2_0 ┆ col2_1 ┆ col2_2 │
│ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    │
│ str    ┆ str    ┆ str    ┆ i64    ┆ i64    ┆ i64    │
╞════════╪════════╪════════╪════════╪════════╪════════╡
│ A      ┆ D      ┆ G      ┆ 0      ┆ 3      ┆ 6      │
│ B      ┆ E      ┆ H      ┆ 1      ┆ 4      ┆ 7      │
│ C      ┆ F      ┆ I      ┆ 2      ┆ 5      ┆ 8      │
└────────┴────────┴────────┴────────┴────────┴────────┘
df.unstack(step=3, how="horizontal")
shape: (3, 6)
┌────────┬────────┬────────┬────────┬────────┬────────┐
│ col1_0 ┆ col1_1 ┆ col1_2 ┆ col2_0 ┆ col2_1 ┆ col2_2 │
│ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    ┆ ---    │
│ str    ┆ str    ┆ str    ┆ i64    ┆ i64    ┆ i64    │
╞════════╪════════╪════════╪════════╪════════╪════════╡
│ A      ┆ B      ┆ C      ┆ 0      ┆ 1      ┆ 2      │
│ D      ┆ E      ┆ F      ┆ 3      ┆ 4      ┆ 5      │
│ G      ┆ H      ┆ I      ┆ 6      ┆ 7      ┆ 8      │
└────────┴────────┴────────┴────────┴────────┴────────┘
```
### **update(**

    other: DataFrame, 
    on: str | Sequence[str] | None = None, 
    how: Literal['left', 'inner'] = 'left'
) → DataFrame

Обновите значения в этом фрейме данных ненулевыми значениями в другом.

**Параметры:**

`other` Фрейм данных, который будет использоваться для обновления значений

`on` Имена столбцов, которые будут объединены. Если ничего не указано, используется количество строк.

`how {‘left’, ‘inner’}` ‘left’ сохранит левые строки таблицы как есть. "inner" удалит строки, которые не найдены в других

Предупреждение

Эта функциональность является экспериментальной и может изменяться, но это не считается кардинальным изменением.

Примечание:

Это синтаксический сахар для левого / внутреннего соединения + коалесцирования

Пример:
```
df = pl.DataFrame(
    {
        "A": [1, 2, 3, 4],
        "B": [400, 500, 600, 700],
    }
)
df
shape: (4, 2)
┌─────┬─────┐
│ A   ┆ B   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 400 │
│ 2   ┆ 500 │
│ 3   ┆ 600 │
│ 4   ┆ 700 │
└─────┴─────┘
new_df = pl.DataFrame(
    {
        "B": [4, None, 6],
        "C": [7, 8, 9],
    }
)
new_df
shape: (3, 2)
┌──────┬─────┐
│ B    ┆ C   │
│ ---  ┆ --- │
│ i64  ┆ i64 │
╞══════╪═════╡
│ 4    ┆ 7   │
│ null ┆ 8   │
│ 6    ┆ 9   │
└──────┴─────┘
df.update(new_df)
shape: (4, 2)
┌─────┬─────┐
│ A   ┆ B   │
│ --- ┆ --- │
│ i64 ┆ i64 │
╞═════╪═════╡
│ 1   ┆ 4   │
│ 2   ┆ 500 │
│ 3   ┆ 6   │
│ 4   ┆ 700 │
└─────┴─────┘
```
### **upsample(**

    time_column: str, 
    *, 
    every: str | timedelta, 
    offset: str | timedelta | None = None, 
    by: str | Sequence[str] | None = None, 
    maintain_order: bool = False
) → Self

Повышайте выборку фрейма данных с регулярной частотой.

**Параметры:**

`time_column` столбец time будет использоваться для определения date_range. Обратите внимание, что этот столбец должен быть отсортирован, чтобы выходные данные имели смысл.

`every` интервал будет начинаться "every’ длительностью 

`offset` измените начало date_range на это смещение.

`by` Сначала сгруппируйте по этим столбцам, а затем увеличьте выборку для каждой группы

`maintain_order` Следите за тем, чтобы порядок был предсказуемым. Это происходит медленнее.

Аргументы `every` и `offset` создаются с
помощью следующего строкового языка:
- 1ns (1 nanosecond)
- 1us (1 microsecond)
- 1ms (1 millisecond)
- 1s (1 second)
- 1m (1 minute)
- 1h (1 hour)
- 1d (1 day)
- 1w (1 week)
- 1mo (1 calendar month)
- 1q (1 calendar quarter)
- 1y (1 calendar year)
- 1i (1 index count)
Или объединить их:
“3d12h4m25s” # 3 дня, 12 часов, 4 минуты и 25 секунд
Суффикс `”_saturating”`, указывающий на то, что даты, слишком большие для
своего месяца, должны быть заполнены при наибольших данных (например, 2022-02-29 -> 2022-02-28)
вместо ошибок.

Возвращает: DataFrame

Результат будет отсортирован по time_column (но обратите внимание, что если передается по столбцам, он будет отсортирован только внутри каждой группы по).

Пример:

Увеличьте выборку фрейма данных на определенный интервал.
```
from datetime import datetime
df = pl.DataFrame(
    {
        "time": [
            datetime(2021, 2, 1),
            datetime(2021, 4, 1),
            datetime(2021, 5, 1),
            datetime(2021, 6, 1),
        ],
        "groups": ["A", "B", "A", "B"],
        "values": [0, 1, 2, 3],
    }
).set_sorted("time")
df.upsample(
    time_column="time", every="1mo", by="groups", maintain_order=True
).select(pl.all().forward_fill())
shape: (7, 3)
┌─────────────────────┬────────┬────────┐
│ time                ┆ groups ┆ values │
│ ---                 ┆ ---    ┆ ---    │
│ datetime[μs]        ┆ str    ┆ i64    │
╞═════════════════════╪════════╪════════╡
│ 2021-02-01 00:00:00 ┆ A      ┆ 0      │
│ 2021-03-01 00:00:00 ┆ A      ┆ 0      │
│ 2021-04-01 00:00:00 ┆ A      ┆ 0      │
│ 2021-05-01 00:00:00 ┆ A      ┆ 2      │
│ 2021-04-01 00:00:00 ┆ B      ┆ 1      │
│ 2021-05-01 00:00:00 ┆ B      ┆ 1      │
│ 2021-06-01 00:00:00 ┆ B      ┆ 3      │
└─────────────────────┴────────┴────────┘
```
### **var(**

    ddof: int = 1
) → Self

Агрегируйте столбцы этого фрейма данных по их значению дисперсии.

**Параметры:**

`ddof` “Дельта-степени свободы”: делитель, используемый при вычислении, равен N - ddof, где N представляет количество элементов. По умолчанию значение ddof равно 1.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
        "ham": ["a", "b", "c"],
    }
)
df.var()
shape: (1, 3)
┌─────┬─────┬──────┐
│ foo ┆ bar ┆ ham  │
│ --- ┆ --- ┆ ---  │
│ f64 ┆ f64 ┆ str  │
╞═════╪═════╪══════╡
│ 1.0 ┆ 1.0 ┆ null │
└─────┴─────┴──────┘
df.var(ddof=0)
shape: (1, 3)
┌──────────┬──────────┬──────┐
│ foo      ┆ bar      ┆ ham  │
│ ---      ┆ ---      ┆ ---  │
│ f64      ┆ f64      ┆ str  │
╞══════════╪══════════╪══════╡
│ 0.666667 ┆ 0.666667 ┆ null │
└──────────┴──────────┴──────┘
```
### **vstack(**

    df: DataFrame, 
    *, 
    in_place: bool = False
) → Self

Увеличьте этот фрейм данных по вертикали, наложив на него фрейм данных.

**Параметры:**

`df` фрейм данных в stack

`in_place` Изменять на месте

Пример:
```
df1 = pl.DataFrame(
    {
        "foo": [1, 2],
        "bar": [6, 7],
        "ham": ["a", "b"],
    }
)
df2 = pl.DataFrame(
    {
        "foo": [3, 4],
        "bar": [8, 9],
        "ham": ["c", "d"],
    }
)
df1.vstack(df2)
shape: (4, 3)
┌─────┬─────┬─────┐
│ foo ┆ bar ┆ ham │
│ --- ┆ --- ┆ --- │
│ i64 ┆ i64 ┆ str │
╞═════╪═════╪═════╡
│ 1   ┆ 6   ┆ a   │
│ 2   ┆ 7   ┆ b   │
│ 3   ┆ 8   ┆ c   │
│ 4   ┆ 9   ┆ d   │
└─────┴─────┴─────┘
```
свойство `width`: int
Получите ширину фрейма данных.

Пример:
```
df = pl.DataFrame({"foo": [1, 2, 3, 4, 5]})
df.width
1
```
### **with_columns(**

    *exprs: IntoExpr | Iterable[IntoExpr], 
    **named_exprs: IntoExpr
) → DataFrame

Добавьте столбцы в этот фрейм данных.

Добавленные столбцы заменят существующие столбцы с тем же именем.

**Параметры:**

`*exprs` Добавляемые столбцы, указанные в качестве позиционных аргументов. Принимает ввод выражения. Строки анализируются как имена столбцов, другие входные данные, не являющиеся выражениями, анализируются как литералы.

`**named_exprs` Добавляемые дополнительные столбцы, указанные в качестве аргументов ключевого слова. Столбцы будут переименованы в соответствии с используемым ключевым словом.

возвращает: Новый фрейм данных с добавленными столбцами.

Примечание:

Создание нового фрейма данных с помощью этого метода не приводит к созданию новой копии существующих данных.

Пример:

Передайте выражение, чтобы добавить его в качестве нового столбца.
```
df = pl.DataFrame(
    {
        "a": [1, 2, 3, 4],
        "b": [0.5, 4, 10, 13],
        "c": [True, True, False, True],
    }
)
df.with_columns((pl.col("a") ** 2).alias("a^2"))
shape: (4, 4)
┌─────┬──────┬───────┬──────┐
│ a   ┆ b    ┆ c     ┆ a^2  │
│ --- ┆ ---  ┆ ---   ┆ ---  │
│ i64 ┆ f64  ┆ bool  ┆ f64  │
╞═════╪══════╪═══════╪══════╡
│ 1   ┆ 0.5  ┆ true  ┆ 1.0  │
│ 2   ┆ 4.0  ┆ true  ┆ 4.0  │
│ 3   ┆ 10.0 ┆ false ┆ 9.0  │
│ 4   ┆ 13.0 ┆ true  ┆ 16.0 │
└─────┴──────┴───────┴──────┘
```
Добавленные столбцы заменят существующие столбцы с тем же именем.
```
df.with_columns(pl.col("a").cast(pl.Float64))
shape: (4, 3)
┌─────┬──────┬───────┐
│ a   ┆ b    ┆ c     │
│ --- ┆ ---  ┆ ---   │
│ f64 ┆ f64  ┆ bool  │
╞═════╪══════╪═══════╡
│ 1.0 ┆ 0.5  ┆ true  │
│ 2.0 ┆ 4.0  ┆ true  │
│ 3.0 ┆ 10.0 ┆ false │
│ 4.0 ┆ 13.0 ┆ true  │
└─────┴──────┴───────┘
```
Несколько столбцов можно добавить, передав список выражений.
```
df.with_columns(
    [
        (pl.col("a") ** 2).alias("a^2"),
        (pl.col("b") / 2).alias("b/2"),
        (pl.col("c").is_not()).alias("not c"),
    ]
)
shape: (4, 6)
┌─────┬──────┬───────┬──────┬──────┬───────┐
│ a   ┆ b    ┆ c     ┆ a^2  ┆ b/2  ┆ not c │
│ --- ┆ ---  ┆ ---   ┆ ---  ┆ ---  ┆ ---   │
│ i64 ┆ f64  ┆ bool  ┆ f64  ┆ f64  ┆ bool  │
╞═════╪══════╪═══════╪══════╪══════╪═══════╡
│ 1   ┆ 0.5  ┆ true  ┆ 1.0  ┆ 0.25 ┆ false │
│ 2   ┆ 4.0  ┆ true  ┆ 4.0  ┆ 2.0  ┆ false │
│ 3   ┆ 10.0 ┆ false ┆ 9.0  ┆ 5.0  ┆ true  │
│ 4   ┆ 13.0 ┆ true  ┆ 16.0 ┆ 6.5  ┆ false │
└─────┴──────┴───────┴──────┴──────┴───────┘
```
Несколько столбцов также могут быть добавлены с использованием позиционных аргументов вместо списка.
```
df.with_columns(
    (pl.col("a") ** 2).alias("a^2"),
    (pl.col("b") / 2).alias("b/2"),
    (pl.col("c").is_not()).alias("not c"),
)
shape: (4, 6)
┌─────┬──────┬───────┬──────┬──────┬───────┐
│ a   ┆ b    ┆ c     ┆ a^2  ┆ b/2  ┆ not c │
│ --- ┆ ---  ┆ ---   ┆ ---  ┆ ---  ┆ ---   │
│ i64 ┆ f64  ┆ bool  ┆ f64  ┆ f64  ┆ bool  │
╞═════╪══════╪═══════╪══════╪══════╪═══════╡
│ 1   ┆ 0.5  ┆ true  ┆ 1.0  ┆ 0.25 ┆ false │
│ 2   ┆ 4.0  ┆ true  ┆ 4.0  ┆ 2.0  ┆ false │
│ 3   ┆ 10.0 ┆ false ┆ 9.0  ┆ 5.0  ┆ true  │
│ 4   ┆ 13.0 ┆ true  ┆ 16.0 ┆ 6.5  ┆ false │
└─────┴──────┴───────┴──────┴──────┴───────┘
```
Используйте аргументы ключевых слов, чтобы легко присвоить имена входным данным вашего выражения.
```
df.with_columns(
    ab=pl.col("a") * pl.col("b"),
    not_c=pl.col("c").is_not(),
)
shape: (4, 5)
┌─────┬──────┬───────┬──────┬───────┐
│ a   ┆ b    ┆ c     ┆ ab   ┆ not_c │
│ --- ┆ ---  ┆ ---   ┆ ---  ┆ ---   │
│ i64 ┆ f64  ┆ bool  ┆ f64  ┆ bool  │
╞═════╪══════╪═══════╪══════╪═══════╡
│ 1   ┆ 0.5  ┆ true  ┆ 0.5  ┆ false │
│ 2   ┆ 4.0  ┆ true  ┆ 8.0  ┆ false │
│ 3   ┆ 10.0 ┆ false ┆ 30.0 ┆ true  │
│ 4   ┆ 13.0 ┆ true  ┆ 52.0 ┆ false │
└─────┴──────┴───────┴──────┴───────┘
```
Выражения с несколькими выходными данными можно автоматически создавать как структуры, включив экспериментальную настройку `Config.set_auto_structify(True):`
```
with pl.Config(auto_structify=True):
    df.drop("c").with_columns(
        diffs=pl.col(["a", "b"]).diff().suffix("_diff"),
    )

shape: (4, 3)
┌─────┬──────┬─────────────┐
│ a   ┆ b    ┆ diffs       │
│ --- ┆ ---  ┆ ---         │
│ i64 ┆ f64  ┆ struct[2]   │
╞═════╪══════╪═════════════╡
│ 1   ┆ 0.5  ┆ {null,null} │
│ 2   ┆ 4.0  ┆ {1,3.5}     │
│ 3   ┆ 10.0 ┆ {1,6.0}     │
│ 4   ┆ 13.0 ┆ {1,3.0}     │
└─────┴──────┴─────────────┘
```
### **with_row_count(**

    name: str = 'row_nr', 
    offset: int = 0
) → Self

Добавьте столбец с индексом 0, который подсчитывает строки.

**Параметры:**

`name` Название добавляемого столбца.

`offset` Начните отсчет строк с этого смещения. По умолчанию = 0

Пример:
```
df = pl.DataFrame(
    {
        "a": [1, 3, 5],
        "b": [2, 4, 6],
    }
)
df.with_row_count()
shape: (3, 3)
┌────────┬─────┬─────┐
│ row_nr ┆ a   ┆ b   │
│ ---    ┆ --- ┆ --- │
│ u32    ┆ i64 ┆ i64 │
╞════════╪═════╪═════╡
│ 0      ┆ 1   ┆ 2   │
│ 1      ┆ 3   ┆ 4   │
│ 2      ┆ 5   ┆ 6   │
└────────┴─────┴─────┘
```
### **write_avro(**

    file: BinaryIO | BytesIO | str | Path, 
    compression: AvroCompression = 'uncompressed'
) → None

Запишите в файл Apache Avro.

**Параметры:**

`file` Путь к файлу, в который должен быть записан файл.

`compression {‘uncompressed’, ‘snappy’, ‘deflate’}` Способ сжатия. По умолчанию используется значение “uncompressed”.

Пример:
```
import pathlib

df = pl.DataFrame(
    {
        "foo": [1, 2, 3, 4, 5],
        "bar": [6, 7, 8, 9, 10],
        "ham": ["a", "b", "c", "d", "e"],
    }
)
path: pathlib.Path = dirpath / "new_file.avro"
df.write_avro(path)
```
### **write_csv(**

    file: None = None, 
    *, 
    has_header: bool = True, 
    separator: str = ',', 
    quote: str = '"', 
    batch_size: int = 1024, 
    datetime_format: str | None = None, 
    date_format: str | None = None, 
    time_format: str | None = None, 
    float_precision: int | None = None, 
    null_value: str | None = None
) → str

**write_csv(**

    file: BytesIO | str | Path, 
    *, 
    has_header: bool = True, 
    separator: str = ',', 
    quote: str = '"', 
    batch_size: int = 1024, 
    datetime_format: str | None = None, 
    date_format: str | None = None, 
    time_format: str | None = None, 
    float_precision: int | None = None, 
    null_value: str | None = None
) → None

Запись в файл значений, разделенных запятыми (CSV).

**Параметры:**

`file` Путь к файлу, в который должен быть записан результат. Если задано значение None (по умолчанию), выходные данные вместо этого возвращаются в виде строки.

`has_header` Следует ли включать заголовок в выходные данные CSV.

`separator` Разделитель в CSV-файле.

`quote` для использования в качестве символа, заключенного в кавычки.

`batch_size` Количество строк, которые будут обработаны в каждом потоке.

`datetime_format` Строка формата со спецификаторами, определенными в chrono Rust crate. Если формат не указан, точность в долях секунды по умолчанию определяется исходя из максимальной временной единицы, найденной в столбцах даты и времени кадра (если таковые имеются).

`date_format` Строка формата со спецификаторами, определенными в chrono Rust crate.

`time_format` Строка формата со спецификаторами, определенными в chrono Rust crate.

`float_precision` Количество знаков после запятой для записи, применяемое как к типам данных Float32, так и к Float64.

`null_value` Строка, представляющая нулевые значения (по умолчанию используется пустая строка).

Пример:
```
import pathlib

df = pl.DataFrame(
    {
        "foo": [1, 2, 3, 4, 5],
        "bar": [6, 7, 8, 9, 10],
        "ham": ["a", "b", "c", "d", "e"],
    }
)
path: pathlib.Path = dirpath / "new_file.csv"
df.write_csv(path, separator=",")
```
### **write_database(**

    table_name: str, 
    connection_uri: str, 
    *, 
    if_exists: DbWriteMode = 'fail', 
    engine: DbWriteEngine = 'sqlalchemy'
) → None

Запишите фрейм polars в базу данных.

**Параметры:**

`table_name` Имя таблицы для добавления или создания в базе данных SQL.

`connection_uri` Uri подключения, например

*“postgresql://username:password@server:port/database”*

`if_exists {‘append’, ‘replace’, ‘fail’}` Режим вставки. ‘replace’ создаст новую таблицу базы данных, перезаписав существующую. ‘append" добавит к существующей таблице. ‘fail’ завершится ошибкой, если таблица уже существует.

`engine {‘sqlalchemy’, ‘adbc’}` Выберите механизм, используемый для записи данных.

### **write_delta(**

    target: str | Path | deltalake.DeltaTable, 
    *, 
    mode: Literal['error', 'append', 'overwrite', 'ignore'] = 'error', 
    overwrite_schema: bool = False, 
    storage_options: dict[str, str] | None = None, 
    delta_write_options: dict[str, Any] | None = None
) → None

Запишите фрейм данных в виде дельта-таблицы.

Примечание: Некоторые типы данных polars, такие как Null, Categorial и Time, не поддерживаются спецификацией протокола delta.

**Параметры:**

`target` URI таблицы или объекта дельта-таблицы.

`mode {‘error’, ‘append’, ‘overwrite’, ‘ignore’}` Как обращаться с существующими данными.

Если ‘error’, выдайте сообщение об ошибке, если таблица уже существует (по умолчанию).

Если ‘append’, то будут добавлены новые данные.

Если ‘overwrite’, таблица будет заменена новыми данными.

Если ‘ignore’, то ничего не будет записано, если таблица уже существует.

`overwrite_schema` Если значение True, то позволяет обновить схему таблицы.

`storage_options` Дополнительные опции для серверных систем хранения данных, поддерживаемых delta lake. Для облачных хранилищ это может включать конфигурации для аутентификации и т.д.

Смотрите список поддерживаемых вариантов хранения для S3 здесь.

Смотрите список поддерживаемых вариантов хранения для GCS здесь.

Смотрите список поддерживаемых вариантов хранилища для Azure здесь.

`delta_write_options` Дополнительные аргументы ключевого слова при написании таблицы Дельта-лейк. Смотрите список поддерживаемых параметров записи здесь.

Пример:

Создайте экземпляр базового фрейма данных:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3, 4, 5],
        "bar": [6, 7, 8, 9, 10],
        "ham": ["a", "b", "c", "d", "e"],
    }
)
```
Запишите фрейм данных в виде таблицы Delta Lake в локальной файловой системе.
```
table_path = "/path/to/delta-table/"
df.write_delta(table_path)  
```
Добавьте данные в существующую таблицу Delta Lake в локальной файловой системе. Примечание: Это приведет к сбою, если схема новых данных не соответствует схеме существующей таблицы.
```
df.write_delta(table_path, mode="append")  
```
Перезапишите таблицу Дельта-Лейк как новую версию. Примечание: Если схема новых и старых данных одинакова, то установка overwrite_schema не требуется.
```
existing_table_path = "/path/to/delta-table/"
df.write_delta(
    existing_table_path, mode="overwrite", overwrite_schema=True
)  
```
Запишите фрейм данных в виде таблицы Delta Lake в хранилище облачных объектов, например S3.
```
table_path = "s3://bucket/prefix/to/delta-table/"
df.write_delta(
    table_path,
    storage_options={
        "AWS_REGION": "THE_AWS_REGION",
        "AWS_ACCESS_KEY_ID": "THE_AWS_ACCESS_KEY_ID",
        "AWS_SECRET_ACCESS_KEY": "THE_AWS_SECRET_ACCESS_KEY",
    },
)  
```
### **write_excel(**

    workbook: Workbook | BytesIO | Path | str | None = None, 
    worksheet: str | None = None, 
    *, 
    position: tuple[int, int] | str = 'A1', 
    table_style: str | dict[str, Any] | None = None, 
    table_name: str | None = None, 
    column_formats: dict[str | tuple[str, ...], str | dict[str, str]] | None = None, 
    dtype_formats: dict[OneOrMoreDataTypes, str] | None = None, 
    conditional_formats: ConditionalFormatDict | None = None, 
    column_totals: ColumnTotalsDefinition | None = None, 
    column_widths: dict[str | tuple[str, ...], int] | int | None = None, 
    row_totals: RowTotalsDefinition | None = None, 
    row_heights: dict[int | tuple[int, ...], int] | int | None = None, 
    sparklines: dict[str, Sequence[str] | dict[str, Any]] | None = None, 
    formulas: dict[str, str | dict[str, str]] | None = None, 
    float_precision: int = 3, 
    has_header: bool = True, 
    autofilter: bool = True, 
    autofit: bool = False, 
    hidden_columns: Sequence[str] | None = None, 
    hide_gridlines: bool = False, 
    sheet_zoom: int | None = None
) → Workbook

Запишите данные фрейма в таблицу в Excel книге / рабочем листе.

**Параметры:**

`workbookWorkbook` Строковое имя или путь к создаваемой рабочей книге, объекту BytesIO для записи в него или открытому xlsxwriter.Объект рабочей книги, который не был закрыт. Если один, то записывает в dataframe.xlsx рабочая книга в рабочем каталоге.

`worksheetstr` Имя целевого листа; если нет, то при создании новой рабочей книги выполняется запись в “Sheet1” (обратите внимание, что для записи в существующую рабочую книгу требуется действительное имя существующего или нового рабочего листа).

`position{str, tuple}` Позиция таблицы в обозначениях Excel (например: “A1”) или целочисленный кортеж (строка, столбец).

`table_style{str, dict}` Именованный стиль таблицы Excel, такой как “Table Style Medium 4”, или словарь параметров {"ключ":значение,}, содержащий один или несколько из следующих ключей: “style”, “first_column”, “last_column”, “banded_columns“, "banded_rows”.

`table_namestr` Имя объекта выходной таблицы на рабочем листе; затем на него можно ссылаться на листе с помощью формул/диаграмм или с помощью последующих операций xlsxwriter.

`column_formatsdict` Словарь {colname:str,} для применения строки формата Excel к заданным столбцам. Форматы, определенные здесь (такие как “дд/мм/гггг”, “0.00%” и т.д.), будут переопределять любые, определенные в dtype_formats (ниже).

`dtype_formatsdict` Словарь {dtype:str,}, который устанавливает формат Excel по умолчанию для данного типа. (Это может быть переопределено для каждого столбца параметром column_formats). Также допустимо использовать группы dtype, такие как pl.FLOAT_DTYPES, в качестве ключа dtype/format, чтобы упростить настройку единообразных целочисленных форматов и форматов с плавающей точкой.

`conditional_formatsdict` Словарь {colname(s):str,}, {colname(s):dict,} или {colname(s):list,}, определяющий параметры условного формата для указанных столбцов.

При указании строкового имени типа должен быть один из допустимых типов xlsxwriter, таких как “3_color_scale”, “data_bar” и т.д.

При предоставлении словаря вы можете использовать любые / все поддерживаемые xlsxwriter опции, включая наборы значков, формулы и т.д.

Предоставление нескольких столбцов в качестве кортежа/ключа приведет к применению единого формата ко всем столбцам - это эффективно при создании тепловой карты, поскольку минимальные/максимальные значения будут определяться по всему диапазону, а не для каждого столбца.

Наконец, вы также можете предоставить список, составленный из приведенных выше опций, чтобы применить более одного условного формата к одному и тому же диапазону.

`column_totals{bool, list, dict}` Добавьте строку с итогом по столбцу в экспортируемую таблицу.

Если значение True, то все числовые столбцы будут иметь соответствующую сумму, используя “sum”.

При передаче строки это должно быть одно из допустимых имен функции total, и все числовые столбцы будут иметь соответствующую сумму, используя эту функцию.

При передаче списка colnames только те, которые указаны, будут иметь общее значение.

Для большего контроля передайте {colname:funcname,} dict.

Допустимыми именами функций total являются “average”, “count_nums”, “count”, “max”, “min”, “std_dev”, “sum” и “var”.

`column_widths{dict, int}` {colname:int,} dict или одно целое число, которое устанавливает (или переопределяет при автоматической установке) ширину столбцов таблицы в целых пиксельных единицах. Если задано как целое число, то для всех столбцов таблицы используется одно и то же значение.

`row_totals{dict, bool}` Добавьте столбец "Общее количество строк" в правую часть экспортируемой таблицы.

Если значение True, в конце таблицы будет добавлен столбец с именем “total”, который применяет функцию “sum” по строкам ко всем числовым столбцам.

При передаче списка/последовательности имен столбцов в сумме будут участвовать только совпадающие столбцы.

Можно также передать словарь {colname:columns,}, чтобы создать один или несколько итоговых столбцов с разными именами, ссылающихся на разные столбцы.

`row_heights{dict, int}` Словарь int или {row_index:int,}, который задает высоту заданных строк (если предоставляется словарь) или всех строк (если предоставляется целое число), которые пересекаются с телом таблицы (включая любой заголовок и общую строку) в целых пиксельных единицах. Обратите внимание, что row_index начинается с нуля и будет строкой заголовка (если только значение has_headers не равно False).

`sparklinesdict` Словарь {colname:list,} или {colname:dict,}, определяющий одну или несколько спарклайнов, которые будут записаны в новый столбец таблицы.

При передаче списка имен столбцов (используемого в качестве источника данных спарклайна) используются настройки спарклайна по умолчанию (например: линейная диаграмма без маркеров).

Для большего контроля может быть предоставлен xlsxwriter-совместимый options dict, и в этом случае доступны три дополнительных ключа, специфичных для polars: “columns”, “insert_before” и “insert_after”. Они позволяют вам определить исходные столбцы и расположить спарклайны относительно других столбцов таблицы. Если директива position не задана, спарклайны добавляются в конец таблицы (например, в крайний правый угол) в том порядке, в котором они указаны.

`formulasdict` Словарь {colname:formula,} или {colname:dict,}, определяющий одну или несколько формул, которые будут записаны в новый столбец таблицы. Обратите внимание, что вам настоятельно рекомендуется использовать структурированные ссылки в ваших формулах везде, где это возможно, чтобы упростить обращение к столбцам по имени.

При указании строковой формулы (например, “=[@colx]*[@coly]”) столбец будет добавлен в конец таблицы (например, в крайний правый угол), после любых спарклайнов по умолчанию и перед любыми row_totals.

Для большей части управления предоставьте словарь параметров со следующими ключами: “формула” (обязательно), один из “insert_before” или “insert_after” и необязательно “return_dtype”. Последнее используется для надлежащего форматирования выходных данных формулы и позволяет ей участвовать в итоговых значениях строк/столбцов.

`float_precision{dict, int}` Количество десятичных знаков по умолчанию, отображаемое для столбцов с плавающей запятой (обратите внимание, что это чисто директива форматирования; фактические значения не округляются).

`has_headerbool` Укажите, следует ли создавать таблицу со строкой заголовка.

`autofilterbool` Если в таблице есть заголовки, обеспечьте возможность автофильтра.

`autofitbool` Рассчитайте ширину отдельных столбцов на основе полученных данных.

`hidden_columnslist` Список столбцов таблицы, которые нужно скрыть на рабочем листе.

`hide_gridlinesbool` Не отображайте никаких линий сетки на выходном листе.

`sheet_zoomint` Установите уровень масштабирования выходного листа по умолчанию.

Примечания:

Словари условного форматирования должны предоставлять определения, совместимые с xlsxwriter; поляры позаботятся о том, как они применяются на рабочем листе относительно относительного положения листа/столбца. Для получения информации о поддерживаемых параметрах смотрите: https://xlsxwriter.readthedocs.io/working_with_conditional_formats.html

Аналогично, словари параметров sparkline должны содержать ключ/значения, совместимые с xlsxwriter, а также обязательный ключ polars “columns”, который определяет исходные данные sparkline; все эти исходные столбцы должны быть смежными. Доступны два других ключа, специфичных для polars, которые помогают определить, где в таблице появляется спарклайн: “insert_after” и “insert_before”. Значением, связанным с этими ключами, должно быть имя столбца в экспортируемой таблице. https://xlsxwriter.readthedocs.io/working_with_sparklines.html

Словари формул должны содержать ключ с именем “formula”, а затем необязательные ключи “insert_after”, “insert_before” и/или “return_dtype”. Эти дополнительные ключи позволяют вводить столбец в таблицу в определенном месте и/или определять тип возвращаемого значения формулы (например: “Int64”, “Float64” и т.д.). Формулы, которые ссылаются на столбцы таблицы, должны использовать синтаксис структурированных ссылок Excel, чтобы гарантировать, что формула применяется правильно и относится к таблице. https://support.microsoft.com/en-us/office/using-structured-references-with-excel-tables-f5ed2452-2337-4f71-bed3-c8ae6d2b276e

Пример:

Создайте экземпляр базового фрейма данных:
```
from random import uniform
from datetime import date

df = pl.DataFrame(
    {
        "dtm": [date(2023, 1, 1), date(2023, 1, 2), date(2023, 1, 3)],
        "num": [uniform(-500, 500), uniform(-500, 500), uniform(-500, 500)],
        "val": [10_000, 20_000, 30_000],
    }
)
```
Экспорт в “dataframe.xlsx ” (имя рабочей книги по умолчанию, если не указано) в рабочем каталоге добавьте итоговые значения столбцов (“сумма”) для всех числовых столбцов, автоматически установите:
```
df.write_excel(column_totals=True, autofit=True)  
```
Запишите фрейм в определенное место на листе, установите именованный стиль таблицы, примените форматирование даты в американском стиле, увеличьте точность с плавающей запятой по умолчанию, примените функцию итога, отличную от стандартной, к одному столбцу, автоподстройка:
```
df.write_excel(  
    position="B4",
    table_style="Table Style Light 16",
    dtype_formats={pl.Date: "mm/dd/yyyy"},
    column_totals={"num": "average"},
    float_precision=6,
    autofit=True,
)
```
Дважды запишите один и тот же фрейм на именованный рабочий лист, применяя разные стили и условное форматирование к каждой таблице, добавляя заголовки таблиц с помощью явной интеграции xlsxwriter:
```
from xlsxwriter import Workbook
with Workbook("multi_frame.xlsx") as wb:  
    # basic/default conditional formatting
    df.write_excel(
        workbook=wb,
        worksheet="data",
        position=(3, 1),  # specify position as (row,col) coordinates
        conditional_formats={"num": "3_color_scale", "val": "data_bar"},
        table_style="Table Style Medium 4",
    )

    # расширенное условное форматирование, пользовательские стили
    df.write_excel(
        workbook=wb,
        worksheet="data",
        position=(len(df) + 7, 1),
        table_style={
            "style": "Table Style Light 4",
            "first_column": True,
        },
        conditional_formats={
            "num": {
                "type": "3_color_scale",
                "min_color": "#76933c",
                "mid_color": "#c4d79b",
                "max_color": "#ebf1de",
            },
            "val": {
                "type": "data_bar",
                "data_bar_2010": True,
                "bar_color": "#9bbb59",
                "bar_negative_color_same": True,
                "bar_negative_border_color_same": True,
            },
        },
        column_formats={"num": "#,##0.000;[White]-#,##0.000"},
        column_widths={"val": 125},
        autofit=True,
    )

    # добавьте несколько заголовков таблиц (в пользовательском формате)
    ws = wb.get_worksheet_by_name("data")
    fmt_title = wb.add_format(
        {
            "font_color": "#4f6228",
            "font_size": 12,
            "italic": True,
            "bold": True,
        }
    )
    ws.write(2, 1, "Basic/default conditional formatting", fmt_title)
    ws.write(len(df) + 6, 1, "Customised conditional formatting", fmt_title)
```
Экспортируйте таблицу, содержащую два разных типа спарклайнов. Используйте параметры по умолчанию для спарклайна “тренд” и настраиваемые параметры (и позиционирование) для спарклайна “+/-” win_loss с форматированием целочисленного типа по умолчанию, итогами по столбцам, тонкой двухцветной тепловой картой и скрытыми линиями сетки рабочего листа:
```
df = pl.DataFrame(
    {
        "id": ["aaa", "bbb", "ccc", "ddd", "eee"],
        "q1": [100, 55, -20, 0, 35],
        "q2": [30, -10, 15, 60, 20],
        "q3": [-50, 0, 40, 80, 80],
        "q4": [75, 55, 25, -10, -55],
    }
)
df.write_excel(  
    table_style="Table Style Light 2",
    # примените формат учета ко всем вариантам integer
    dtype_formats={pl.INTEGER_DTYPES: "#,##0_);(#,##0)"},
    sparklines={
        # параметры по умолчанию; просто укажите исходные столбцы
        "trend": ["q1", "q2", "q3", "q4"],
        # индивидуальный тип спарклайна с директивой позиционирования
        "+/-": {
            "columns": ["q1", "q2", "q3", "q4"],
            "insert_after": "id",
            "type": "win_loss",
        },
    },
    conditional_formats={
        # создайте единую многоколоночную тепловую карту
        ("q1", "q2", "q3", "q4"): {
            "type": "2_color_scale",
            "min_color": "#95b3d7",
            "max_color": "#ffffff",
        },
    },
    column_totals=["q1", "q2", "q3", "q4"],
    row_totals=True,
    hide_gridlines=True,
)
```
Экспортируйте таблицу, содержащую столбец на основе формулы Excel, который вычисляет стандартизированный Z-критерий, показывая использование структурированных ссылок в сочетании с директивами позиционирования, итоговыми значениями столбцов и пользовательским форматированием.
```
df = pl.DataFrame(
    {
        "id": ["a123", "b345", "c567", "d789", "e101"],
        "points": [99, 45, 50, 85, 35],
    }
)
df.write_excel(  
    table_style={
        "style": "Table Style Medium 15",
        "first_column": True,
    },
    column_formats={
        "id": {"font": "Consolas"},
        "points": {"align": "center"},
        "z-score": {"align": "center"},
    },
    column_totals="average",
    formulas={
        "z-score": {
            # используйте структурированные ссылки для ссылок на столбцы таблицы и строку "итоги"
            "formula": "=STANDARDIZE([@points], [[#Totals],[points]], STDEV([points]))",
            "insert_after": "points",
            "return_dtype": pl.Float64,
        }
    },
    hide_gridlines=True,
    sheet_zoom=125,
)
```
### **write_ipc(**
    
    file: None, 
    compression: IpcCompression = 'uncompressed'
) → BytesIO

**write_ipc(**

    file: BinaryIO | BytesIO | str | Path, 
    compression: IpcCompression = 'uncompressed'
) → None

Запишите в двоичный поток Arrow IPC или файл Feather.

**Параметры:**

`file` Путь, в который должны быть записаны данные IPC. Если задано значение None, выходные данные возвращаются в виде объекта BytesIO.

`compression {‘uncompressed’, ‘lz4’, ‘zstd’}` Способ сжатия. По умолчанию используется значение “uncompressed”.

Пример:
```
import pathlib

df = pl.DataFrame(
    {
        "foo": [1, 2, 3, 4, 5],
        "bar": [6, 7, 8, 9, 10],
        "ham": ["a", "b", "c", "d", "e"],
    }
)
path: pathlib.Path = dirpath / "new_file.arrow"
df.write_ipc(path)
```
### **write_json(**

    file: None = None, 
    *, 
    pretty: bool = False, 
    row_oriented: bool = False
) → str

**write_json(**

    file: IOBase | str | Path, 
    *, 
    pretty: bool = False, 
    row_oriented: bool = False
) → None

Сериализовать в JSON-представление.

**Параметры:**

`file` Путь к файлу, в который должен быть записан результат. Если задано значение None (по умолчанию), выходные данные вместо этого возвращаются в виде строки.

`pretty` Симпатичная сериализация json.

`row_oriented` Запись в json, ориентированный на строку. Это происходит медленнее, но чаще встречается.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
    }
)
df.write_json()
'{"columns":[{"name":"foo","datatype":"Int64","values":[1,2,3]},{"name":"bar","datatype":"Int64","values":[6,7,8]}]}'
df.write_json(row_oriented=True)
'[{"foo":1,"bar":6},{"foo":2,"bar":7},{"foo":3,"bar":8}]'
```
### **write_ndjson(**

    file: None = None
) → str

**write_ndjson(**

    file: IOBase | str | Path
) → None

Сериализовать в JSON-представление с разделителями новой строки.

**Параметры:**

`file` Путь к файлу, в который должен быть записан результат. Если задано значение None (по умолчанию), выходные данные вместо этого возвращаются в виде строки.

Пример:
```
df = pl.DataFrame(
    {
        "foo": [1, 2, 3],
        "bar": [6, 7, 8],
    }
)

df.write_ndjson()
'{"foo":1,"bar":6}\n{"foo":2,"bar":7}\n{"foo":3,"bar":8}\n'
```
### **write_parquet(**

    file: str | Path | BytesIO, 
    *, 
    compression: ParquetCompression = 'zstd', 
    compression_level: int | None = None, 
    statistics: bool = False, 
    row_group_size: int | None = None, 
    use_pyarrow: bool = False, 
    pyarrow_options: dict[str, object] | None = None
) → None

Запишите в файл Apache Parquet.

**Параметры:**

`file` Путь к файлу, в который должен быть записан файл.

`compression {‘lz4’, ‘uncompressed’, ‘snappy’, ‘gzip’, ‘lzo’, ‘brotli’, ‘zstd’}` Выберите “zstd” для получения хорошей производительности сжатия. Выберите “lz4” для быстрого сжатия/распаковки. Выберите “snappy” для большей гарантии обратной совместимости при работе со старыми считывателями parquet.

`compression_level` Используемый уровень сжатия. Более высокое сжатие означает меньший размер файлов на диске.

“gzip” : min-level: 0, max-level: 10.

“brotli” : min-level: 0, max-level: 11.

“zstd” : min-level: 1, max-level: 22.

`statistics` Запишите статистику в заголовки parquet. Для этого требуется дополнительный компьютер.

`row_group_size` Размер групп строк в количестве строк. Значение по умолчанию равно 512^2 строкам.

`use_pyarrow` Используйте реализацию parquet на C++ против реализации Rust parquet. На данный момент C++ поддерживает больше функций.

`pyarrow_options` Аргументы, переданные в pyarrow.parquet.write_table.

Пример:
```
import pathlib

df = pl.DataFrame(
    {
        "foo": [1, 2, 3, 4, 5],
        "bar": [6, 7, 8, 9, 10],
        "ham": ["a", "b", "c", "d", "e"],
    }
)
path: pathlib.Path = dirpath / "new_file.parquet"
df.write_parquet(path)
```